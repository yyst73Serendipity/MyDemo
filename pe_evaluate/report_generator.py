"""
æŠ¥å‘Šç”Ÿæˆæ¨¡å— - æ–°ç‰ˆ9ç»´åº¦è¯„åˆ†ä½“ç³»
ç”ŸæˆMarkdownæ ¼å¼çš„è¯¦ç»†è¯„ä¼°æŠ¥å‘Š
"""

import os
from datetime import datetime
from typing import Dict, List, Any


class ReportGenerator:
    """è¯„ä¼°æŠ¥å‘Šç”Ÿæˆå™¨ - æ”¯æŒ8ä¸ªè€ƒå¯Ÿç‚¹çš„è¯¦ç»†æŠ¥å‘Š"""
    
    def __init__(self, output_dir: str):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # è€ƒå¯Ÿç‚¹åç§°æ˜ å°„
        self.dimension_names = {
            'A': 'A. æ ¼å¼å®Œæ•´æ€§',
            'B': 'B. èº«ä»½ä¸èŒä¸šåŸºç¡€åŠ è½½',
            'C': 'C. è¯­è¨€é£æ ¼åŸºç¡€',
            'D': 'D. çŸ›ç›¾æ€§å‘ˆç°ï¼ˆè…¹é»‘ä¸æ¸©è‰¯ï¼‰',
            'E': 'E. ç‰¹å®šç‰¹å¾è§¦å‘',
            'F': 'F. èŒä¸šéšå–»è¿ç”¨',
            'G': 'G. æ–‡æœ¬è‡ªç„¶æ€§ä¸ä»£å…¥æ„Ÿ',
            'H': 'H. æƒ…ç»ªè¡¨è¾¾çš„ç»†è…»åº¦'
        }
    
    def generate_report(self, 
                       test_results: Dict[str, Any],
                       test_cases: List[Dict[str, Any]]) -> str:
        """
        ç”Ÿæˆå®Œæ•´çš„è¯„ä¼°æŠ¥å‘Š
        
        Args:
            test_results: æ‰€æœ‰æ¨¡å‹çš„æµ‹è¯•ç»“æœ
            test_cases: æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
        
        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = os.path.join(self.output_dir, f"evaluation_report_{timestamp}.md")
        
        with open(report_path, 'w', encoding='utf-8') as f:
            # æ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯
            f.write(self._generate_header())
            
            # æµ‹è¯•æ¦‚è§ˆ
            f.write(self._generate_overview(test_results, test_cases))
            
            # æ¨¡å‹ç»¼åˆå¯¹æ¯”
            f.write(self._generate_comprehensive_comparison(test_results))
            
            # æ¯ä¸ªæ¨¡å‹çš„è¯¦ç»†æµ‹è¯•ç»“æœ
            for model_name, results in test_results.items():
                f.write(self._generate_model_detailed_results(model_name, results, test_cases))
            
            # äººå·¥è¯„ä»·æŒ‡å—
            f.write(self._generate_manual_review_guide())
        
        return report_path
    
    def _generate_header(self) -> str:
        """ç”ŸæˆæŠ¥å‘Šå¤´éƒ¨"""
        current_time = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
        return f"""# Aå…ˆç”Ÿè§’è‰²Promptè¯„æµ‹æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {current_time}  
**è¯„ä¼°ä½“ç³»**: ä¸‰ç»´åº¦å…«è€ƒå¯Ÿç‚¹ï¼ˆA-Hï¼‰+ åŠ æƒæ€»åˆ†åˆ¶

---

"""
    
    def _generate_overview(self, test_results: Dict[str, Any], 
                          test_cases: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆæµ‹è¯•æ¦‚è§ˆ"""
        num_models = len(test_results)
        num_tests = len(test_cases)
        
        content = f"""## ğŸ“Š æµ‹è¯•æ¦‚è§ˆ

- **æµ‹è¯•ç”¨ä¾‹æ•°**: {num_tests} ä¸ª
- **å‚ä¸æ¨¡å‹**: {num_models} ä¸ª
- **è¯„ä¼°ä½“ç³»**: ä¸‰ç»´åº¦å…«è€ƒå¯Ÿç‚¹ï¼ˆæ»¡åˆ†40åˆ†ï¼ŒåŠ æƒåæ¢ç®—ä¸º100åˆ†ï¼‰

### è¯„ä¼°ç»´åº¦è¯´æ˜

#### ç»´åº¦ä¸€ï¼šåŸºç¡€æŒ‡ä»¤éµå¾ªåº¦ï¼ˆæƒé‡30%ï¼‰
- A. æ ¼å¼å®Œæ•´æ€§ (0-5åˆ†)
- B. èº«ä»½ä¸èŒä¸šåŸºç¡€åŠ è½½ (0-5åˆ†)
- C. è¯­è¨€é£æ ¼åŸºç¡€ (0-5åˆ†)

#### ç»´åº¦äºŒï¼šæ ¸å¿ƒäººè®¾åŒ¹é…åº¦ï¼ˆæƒé‡40%ï¼‰
- D. çŸ›ç›¾æ€§å‘ˆç°ï¼ˆè…¹é»‘ä¸æ¸©è‰¯ï¼‰(0-5åˆ†)
- E. ç‰¹å®šç‰¹å¾è§¦å‘ (0-5åˆ†)
- F. èŒä¸šéšå–»è¿ç”¨ (0-5åˆ†)

#### ç»´åº¦ä¸‰ï¼šè¾“å‡ºè¡¨è¾¾æµç•…åº¦ï¼ˆæƒé‡30%ï¼‰
- G. æ–‡æœ¬è‡ªç„¶æ€§ä¸ä»£å…¥æ„Ÿ (0-5åˆ†)
- H. æƒ…ç»ªè¡¨è¾¾çš„ç»†è…»åº¦ (0-5åˆ†)

### åˆ†æ•°è®¡ç®—å…¬å¼

```
å•ç»´åº¦å¾—åˆ† = è¯¥ç»´åº¦å„è€ƒå¯Ÿç‚¹å¾—åˆ†ä¹‹å’Œ / è€ƒå¯Ÿç‚¹æ•°é‡
åŠ æƒå¾—åˆ† = ç»´åº¦ä¸€Ã—30% + ç»´åº¦äºŒÃ—40% + ç»´åº¦ä¸‰Ã—30%
æ€»åˆ†(100åˆ†åˆ¶) = åŠ æƒå¾—åˆ† Ã— 20
```

---

"""
        return content
    
    def _generate_comprehensive_comparison(self, test_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ¨¡å‹ç»¼åˆå¯¹æ¯”"""
        content = "## ğŸ† æ¨¡å‹ç»¼åˆè¡¨ç°å¯¹æ¯”\n\n"
        
        model_stats = []
        
        for model_name, results in test_results.items():
            if not results:
                continue
            
            # æ”¶é›†è¯¥æ¨¡å‹æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹çš„è¯„ä¼°ç»“æœ
            evaluations = [r['evaluation'] for r in results.values() if 'evaluation' in r and r['evaluation']]
            
            if not evaluations:
                continue
            
            # è®¡ç®—å¹³å‡åˆ†
            avg_score_100 = sum(e['total_score_100'] for e in evaluations) / len(evaluations)
            avg_dim1 = sum(e['dimension_scores']['ç»´åº¦ä¸€_åŸºç¡€æŒ‡ä»¤éµå¾ªåº¦']['score'] for e in evaluations) / len(evaluations)
            avg_dim2 = sum(e['dimension_scores']['ç»´åº¦äºŒ_æ ¸å¿ƒäººè®¾åŒ¹é…åº¦']['score'] for e in evaluations) / len(evaluations)
            avg_dim3 = sum(e['dimension_scores']['ç»´åº¦ä¸‰_è¾“å‡ºè¡¨è¾¾æµç•…åº¦']['score'] for e in evaluations) / len(evaluations)
            
            # è¯„çº§
            if avg_score_100 >= 90:
                rating = "â­â­â­â­â­ ä¼˜ç§€"
            elif avg_score_100 >= 80:
                rating = "â­â­â­â­ è‰¯å¥½"
            elif avg_score_100 >= 70:
                rating = "â­â­â­ ä¸­ç­‰"
            elif avg_score_100 >= 60:
                rating = "â­â­ åŠæ ¼"
            else:
                rating = "â­ å¾…æ”¹è¿›"
            
            model_stats.append({
                'name': model_name,
                'avg_score_100': avg_score_100,
                'avg_dim1': avg_dim1,
                'avg_dim2': avg_dim2,
                'avg_dim3': avg_dim3,
                'rating': rating,
                'test_count': len(evaluations)
            })
        
        # æŒ‰æ€»åˆ†æ’åº
        model_stats.sort(key=lambda x: x['avg_score_100'], reverse=True)
        
        # ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
        content += "| æ’å | æ¨¡å‹åç§° | åŠ æƒæ€»åˆ† | ç»´åº¦ä¸€ | ç»´åº¦äºŒ | ç»´åº¦ä¸‰ | ç»¼åˆè¯„çº§ |\n"
        content += "|------|---------|---------|--------|--------|--------|----------|\n"
        
        for rank, ms in enumerate(model_stats, 1):
            content += f"| {rank} | {ms['name']} | **{ms['avg_score_100']:.1f}/100** | {ms['avg_dim1']:.2f}/5 | {ms['avg_dim2']:.2f}/5 | {ms['avg_dim3']:.2f}/5 | {ms['rating']} |\n"
        
        content += "\n**è¯´æ˜**ï¼š\n"
        content += "- åŠ æƒæ€»åˆ† = ç»´åº¦ä¸€Ã—30% + ç»´åº¦äºŒÃ—40% + ç»´åº¦ä¸‰Ã—30%ï¼Œæ¢ç®—ä¸º100åˆ†åˆ¶\n"
        content += "- ç»´åº¦ä¸€ï¼šåŸºç¡€æŒ‡ä»¤éµå¾ªåº¦ï¼ˆA+B+Cï¼‰/3\n"
        content += "- ç»´åº¦äºŒï¼šæ ¸å¿ƒäººè®¾åŒ¹é…åº¦ï¼ˆD+E+Fï¼‰/3\n"
        content += "- ç»´åº¦ä¸‰ï¼šè¾“å‡ºè¡¨è¾¾æµç•…åº¦ï¼ˆG+Hï¼‰/2\n\n"
        
        content += "---\n\n"
        return content
    
    def _generate_model_detailed_results(self, model_name: str, 
                                        results: Dict[str, Any],
                                        test_cases: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆå•ä¸ªæ¨¡å‹çš„è¯¦ç»†æµ‹è¯•ç»“æœ"""
        content = f"## ğŸ¤– {model_name} - è¯¦ç»†æµ‹è¯•ç»“æœ\n\n"
        
        # æ”¶é›†è¯„ä¼°ç»“æœ
        evaluations = [r['evaluation'] for r in results.values() if 'evaluation' in r and r['evaluation']]
        
        if not evaluations:
            content += "âš ï¸ è¯¥æ¨¡å‹æœªèƒ½å®Œæˆæœ‰æ•ˆçš„æµ‹è¯•\n\n---\n\n"
            return content
        
        # è®¡ç®—è¯¥æ¨¡å‹çš„æ±‡æ€»æ•°æ®
        avg_score_100 = sum(e['total_score_100'] for e in evaluations) / len(evaluations)
        avg_dim1 = sum(e['dimension_scores']['ç»´åº¦ä¸€_åŸºç¡€æŒ‡ä»¤éµå¾ªåº¦']['score'] for e in evaluations) / len(evaluations)
        avg_dim2 = sum(e['dimension_scores']['ç»´åº¦äºŒ_æ ¸å¿ƒäººè®¾åŒ¹é…åº¦']['score'] for e in evaluations) / len(evaluations)
        avg_dim3 = sum(e['dimension_scores']['ç»´åº¦ä¸‰_è¾“å‡ºè¡¨è¾¾æµç•…åº¦']['score'] for e in evaluations) / len(evaluations)
        
        # ç”Ÿæˆæ±‡æ€»è¡¨æ ¼
        content += f"### ç»¼åˆè¯„åˆ†æ€»è§ˆ\n\n"
        content += f"**åŠ æƒæ€»åˆ†**: {avg_score_100:.1f}/100\n\n"
        
        content += "| ç»´åº¦ | å¹³å‡å¾—åˆ† | æƒé‡ | åŠ æƒåˆ† | ç™¾åˆ†æ¯” |\n"
        content += "|------|---------|------|--------|--------|\n"
        content += f"| ç»´åº¦ä¸€ï¼šåŸºç¡€æŒ‡ä»¤éµå¾ªåº¦ | {avg_dim1:.2f}/5.0 | 30% | {avg_dim1*0.3:.2f} | {avg_dim1/5*100:.1f}% |\n"
        content += f"| ç»´åº¦äºŒï¼šæ ¸å¿ƒäººè®¾åŒ¹é…åº¦ | {avg_dim2:.2f}/5.0 | 40% | {avg_dim2*0.4:.2f} | {avg_dim2/5*100:.1f}% |\n"
        content += f"| ç»´åº¦ä¸‰ï¼šè¾“å‡ºè¡¨è¾¾æµç•…åº¦ | {avg_dim3:.2f}/5.0 | 30% | {avg_dim3*0.3:.2f} | {avg_dim3/5*100:.1f}% |\n"
        content += f"| **æ€»è®¡** | - | **100%** | **{(avg_dim1*0.3+avg_dim2*0.4+avg_dim3*0.3):.2f}** | **{avg_score_100:.1f}%** |\n\n"
        
        content += "---\n\n"
        
        # é€ä¸ªæµ‹è¯•ç”¨ä¾‹è¯¦ç»†å±•ç¤º
        for test_case in test_cases:
            test_id = test_case['id']
            
            if test_id not in results:
                continue
            
            result = results[test_id]
            response = result.get('response', '')
            evaluation = result.get('evaluation', None)
            
            if not evaluation:
                continue
            
            content += self._generate_test_case_detail(test_case, response, evaluation)
        
        # æ·»åŠ æ±‡æ€»è¡¨
        content += self._generate_model_summary_table(results, test_cases)
        
        content += "---\n\n"
        return content
    
    def _generate_test_case_detail(self, test_case: Dict, response: str, evaluation: Dict) -> str:
        """ç”Ÿæˆå•ä¸ªæµ‹è¯•ç”¨ä¾‹çš„è¯¦ç»†è¯„åˆ†"""
        test_id = test_case['id']
        category = test_case['category']
        
        content = f"### æµ‹è¯•ç”¨ä¾‹ {test_id}: {category}\n\n"
        content += f"**æµ‹è¯•æ„å›¾**: {test_case['intent']}\n\n"
        content += f"**è¾“å…¥å†…å®¹**:\n> {test_case['input']}\n\n"
        
        # æ˜¾ç¤ºæ¨¡å‹å›å¤
        content += "**æ¨¡å‹å®Œæ•´å›å¤**:\n\n"
        for line in response.split('\n'):
            content += f"> {line}\n"
        content += "\n"
        
        # æ˜¾ç¤ºè¯„åˆ†ç»“æœ
        scores = evaluation['scores']
        dim_scores = evaluation['dimension_scores']
        
        content += "#### ğŸ“Š å…«ç»´åº¦è¯„åˆ†è¯¦æƒ…\n\n"
        
        # ç»´åº¦ä¸€
        content += "##### ç»´åº¦ä¸€ï¼šåŸºç¡€æŒ‡ä»¤éµå¾ªåº¦\n\n"
        content += "| è€ƒå¯Ÿç‚¹ | å¾—åˆ† | ç½®ä¿¡åº¦ | è¯„åˆ†ç†ç”± |\n"
        content += "|--------|------|--------|----------|\n"
        for key in ['A', 'B', 'C']:
            score_data = scores[key]
            stars = self._get_stars(score_data['score'])
            confidence_cn = {'high': 'é«˜', 'medium': 'ä¸­', 'low': 'ä½'}.get(score_data['confidence'], 'ä¸­')
            content += f"| {self.dimension_names[key]} | {score_data['score']}/5 {stars} | {confidence_cn} | {score_data['reason']} |\n"
        
        dim1_score = dim_scores['ç»´åº¦ä¸€_åŸºç¡€æŒ‡ä»¤éµå¾ªåº¦']['score']
        content += f"\n**ç»´åº¦ä¸€å¾—åˆ†**: {dim1_score:.2f}/5.0 ({dim1_score/5*100:.1f}%)\n\n"
        
        # ç»´åº¦äºŒ
        content += "##### ç»´åº¦äºŒï¼šæ ¸å¿ƒäººè®¾åŒ¹é…åº¦\n\n"
        content += "| è€ƒå¯Ÿç‚¹ | å¾—åˆ† | ç½®ä¿¡åº¦ | è¯„åˆ†ç†ç”± |\n"
        content += "|--------|------|--------|----------|\n"
        for key in ['D', 'E', 'F']:
            score_data = scores[key]
            stars = self._get_stars(score_data['score'])
            confidence_cn = {'high': 'é«˜', 'medium': 'ä¸­', 'low': 'ä½'}.get(score_data['confidence'], 'ä¸­')
            content += f"| {self.dimension_names[key]} | {score_data['score']}/5 {stars} | {confidence_cn} | {score_data['reason']} |\n"
        
        dim2_score = dim_scores['ç»´åº¦äºŒ_æ ¸å¿ƒäººè®¾åŒ¹é…åº¦']['score']
        content += f"\n**ç»´åº¦äºŒå¾—åˆ†**: {dim2_score:.2f}/5.0 ({dim2_score/5*100:.1f}%)\n\n"
        
        # ç»´åº¦ä¸‰
        content += "##### ç»´åº¦ä¸‰ï¼šè¾“å‡ºè¡¨è¾¾æµç•…åº¦\n\n"
        content += "| è€ƒå¯Ÿç‚¹ | å¾—åˆ† | ç½®ä¿¡åº¦ | è¯„åˆ†ç†ç”± |\n"
        content += "|--------|------|--------|----------|\n"
        for key in ['G', 'H']:
            score_data = scores[key]
            stars = self._get_stars(score_data['score'])
            confidence_cn = {'high': 'é«˜', 'medium': 'ä¸­', 'low': 'ä½'}.get(score_data['confidence'], 'ä¸­')
            content += f"| {self.dimension_names[key]} | {score_data['score']}/5 {stars} | {confidence_cn} | {score_data['reason']} |\n"
        
        dim3_score = dim_scores['ç»´åº¦ä¸‰_è¾“å‡ºè¡¨è¾¾æµç•…åº¦']['score']
        content += f"\n**ç»´åº¦ä¸‰å¾—åˆ†**: {dim3_score:.2f}/5.0 ({dim3_score/5*100:.1f}%)\n\n"
        
        # æ€»åˆ†
        content += "#### ğŸ¯ æœ¬æ¬¡æµ‹è¯•æ€»åˆ†\n\n"
        content += f"- **åŸå§‹æ€»åˆ†**: {evaluation['raw_total']}/{evaluation['raw_max']} ({evaluation['raw_total']/evaluation['raw_max']*100:.1f}%)\n"
        content += f"- **åŠ æƒå¾—åˆ†**: {evaluation['weighted_score']:.2f}/5.0\n"
        content += f"- **æ¢ç®—æ€»åˆ†**: **{evaluation['total_score_100']:.1f}/100**\n\n"
        
        # äººå·¥è°ƒæ•´åŒºåŸŸ
        content += "#### ğŸ‘¤ äººå·¥è¯„ä»·ä¸è°ƒæ•´\n\n"
        content += "**éœ€è¦äººå·¥å¤æ ¸çš„è€ƒå¯Ÿç‚¹**:\n"
        
        needs_review = []
        for key, score_data in scores.items():
            if score_data.get('manual_adjust_hint'):
                needs_review.append(f"- **{self.dimension_names[key]}**: {score_data['manual_adjust_hint']}")
        
        if needs_review:
            content += '\n'.join(needs_review) + '\n\n'
        else:
            content += "- æš‚æ— éœ€è¦é‡ç‚¹å¤æ ¸çš„é¡¹ç›®ï¼ˆæ‰€æœ‰ç½®ä¿¡åº¦å‡ä¸ºä¸­æˆ–é«˜ï¼‰\n\n"
        
        content += "**äººå·¥è°ƒæ•´åŒºåŸŸ** (å¡«å†™ä¿®æ”¹åçš„åˆ†æ•°):\n\n"
        content += "| è€ƒå¯Ÿç‚¹ | è‡ªåŠ¨è¯„åˆ† | äººå·¥è°ƒåˆ† | è°ƒæ•´ç†ç”± |\n"
        content += "|--------|---------|----------|----------|\n"
        for key in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']:
            content += f"| {self.dimension_names[key]} | {scores[key]['score']}/5 | ___/5 | __________ |\n"
        
        content += "\n**ç»¼åˆäººå·¥è¯„ä»·**:  \n[è¯·åœ¨æ­¤å¡«å†™å¯¹æœ¬æ¬¡å›å¤çš„æ•´ä½“è¯„ä»·]\n\n"
        
        content += "---\n\n"
        return content
    
    def _generate_model_summary_table(self, results: Dict, test_cases: List[Dict]) -> str:
        """ç”Ÿæˆæ¨¡å‹æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹çš„æ±‡æ€»è¡¨"""
        content = "### ğŸ“‹ æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹æ±‡æ€»è¡¨\n\n"
        
        content += "| æµ‹è¯•ID | ç±»åˆ« | ç»´åº¦ä¸€ | ç»´åº¦äºŒ | ç»´åº¦ä¸‰ | åŠ æƒå¾—åˆ† | æ€»åˆ†/100 |\n"
        content += "|--------|------|--------|--------|--------|----------|----------|\n"
        
        total_dim1 = 0
        total_dim2 = 0
        total_dim3 = 0
        total_weighted = 0
        total_score_100 = 0
        count = 0
        
        for test_case in test_cases:
            test_id = test_case['id']
            if test_id not in results or not results[test_id].get('evaluation'):
                continue
            
            eval_data = results[test_id]['evaluation']
            dim1 = eval_data['dimension_scores']['ç»´åº¦ä¸€_åŸºç¡€æŒ‡ä»¤éµå¾ªåº¦']['score']
            dim2 = eval_data['dimension_scores']['ç»´åº¦äºŒ_æ ¸å¿ƒäººè®¾åŒ¹é…åº¦']['score']
            dim3 = eval_data['dimension_scores']['ç»´åº¦ä¸‰_è¾“å‡ºè¡¨è¾¾æµç•…åº¦']['score']
            weighted = eval_data['weighted_score']
            score_100 = eval_data['total_score_100']
            
            content += f"| {test_id} | {test_case['category'][:8]} | {dim1:.2f} | {dim2:.2f} | {dim3:.2f} | {weighted:.2f} | **{score_100:.1f}** |\n"
            
            total_dim1 += dim1
            total_dim2 += dim2
            total_dim3 += dim3
            total_weighted += weighted
            total_score_100 += score_100
            count += 1
        
        if count > 0:
            content += f"| **å¹³å‡** | - | **{total_dim1/count:.2f}** | **{total_dim2/count:.2f}** | **{total_dim3/count:.2f}** | **{total_weighted/count:.2f}** | **{total_score_100/count:.1f}** |\n"
        
        content += "\n"
        return content
    
    def _get_stars(self, score: int) -> str:
        """æ ¹æ®åˆ†æ•°è¿”å›æ˜Ÿæ˜Ÿ"""
        return 'â­' * score
    
    def _generate_manual_review_guide(self) -> str:
        """ç”Ÿæˆäººå·¥å¤æ ¸æŒ‡å—"""
        content = "## ğŸ“ äººå·¥å¤æ ¸æŒ‡å—\n\n"
        
        content += "### ä¸ºä»€ä¹ˆéœ€è¦äººå·¥å¤æ ¸ï¼Ÿ\n\n"
        content += "è‡ªåŠ¨è¯„ä¼°ç³»ç»Ÿåœ¨ä»¥ä¸‹è€ƒå¯Ÿç‚¹çš„åˆ¤æ–­ä¸Šå­˜åœ¨å±€é™æ€§ï¼š\n\n"
        content += "- **D. çŸ›ç›¾æ€§å‘ˆç°**ï¼ˆç½®ä¿¡åº¦ï¼šä½ï¼‰- åå·®æ„Ÿå’Œè®½åˆºåº¦åˆ¤æ–­ä¸»è§‚æ€§å¼º\n"
        content += "- **G. æ–‡æœ¬è‡ªç„¶æ€§**ï¼ˆç½®ä¿¡åº¦ï¼šä½ï¼‰- ä»£å…¥æ„Ÿå’Œäººæƒ…å‘³éš¾ä»¥é‡åŒ–\n"
        content += "- **H. æƒ…ç»ªè¡¨è¾¾**ï¼ˆç½®ä¿¡åº¦ï¼šä½ï¼‰- ç»†è…»åº¦éœ€è¦æ·±åº¦è¯­ä¹‰ç†è§£\n\n"
        
        content += "### äººå·¥å¤æ ¸å»ºè®®ç»´åº¦\n\n"
        content += "1. **è§’è‰²ä¸€è‡´æ€§** - 8ä¸ªæµ‹è¯•ç”¨ä¾‹ä¸­ï¼Œè§’è‰²äººè®¾æ˜¯å¦ä¿æŒä¸€è‡´ï¼Ÿ\n"
        content += "2. **æƒ…æ„ŸçœŸå®åº¦** - è…¹é»‘ä¸æ¸©è‰¯çš„åå·®æ˜¯å¦è‡ªç„¶å¯ä¿¡ï¼Ÿ\n"
        content += "3. **è¯­è¨€é­…åŠ›** - æªè¾æ˜¯å¦ä¼˜é›…ï¼Œæ˜¯å¦æœ‰å»ºç­‘å¸ˆçš„ä¸“ä¸šæ°”è´¨ï¼Ÿ\n"
        content += "4. **åˆ›æ„äº®ç‚¹** - æ˜¯å¦æœ‰ä»¤äººå°è±¡æ·±åˆ»çš„è¡¨è¾¾æˆ–æ¯”å–»ï¼Ÿ\n"
        content += "5. **æ²‰æµ¸æ„Ÿ** - é˜…è¯»æ—¶æ˜¯å¦æ„Ÿè§‰åœ¨ä¸çœŸå®è§’è‰²å¯¹è¯ï¼Ÿ\n\n"
        
        content += "### äººå·¥è¯„åˆ†å‚è€ƒè¡¨\n\n"
        content += "| ç»¼åˆè¯„ä»· | åˆ†æ•°èŒƒå›´ | ç‰¹å¾æè¿° |\n"
        content += "|---------|---------|----------|\n"
        content += "| å®Œç¾æ¼”ç» | 90-100 | å®Œå…¨ç¬¦åˆäººè®¾ï¼Œæœ‰æƒŠè‰³è¡¨ç°ï¼Œæ²‰æµ¸æ„Ÿæå¼º |\n"
        content += "| ä¼˜ç§€ | 80-89 | è§’è‰²ç¨³å®šï¼Œè¡¨è¾¾å‡ºè‰²ï¼Œå¶æœ‰å°ç‘•ç–µ |\n"
        content += "| è‰¯å¥½ | 70-79 | åŸºæœ¬ç¬¦åˆäººè®¾ï¼Œè¡¨è¾¾æµç•…ï¼Œä½†ç¼ºä¹äº®ç‚¹ |\n"
        content += "| åŠæ ¼ | 60-69 | èƒ½å®Œæˆè§’è‰²æ‰®æ¼”ï¼Œä½†äººè®¾ä¸å¤Ÿé²œæ˜ |\n"
        content += "| ä¸åŠæ ¼ | <60 | é¢‘ç¹å‡ºæˆï¼Œè§’è‰²æ··ä¹±ï¼Œè¡¨è¾¾ç”Ÿç¡¬ |\n\n"
        
        content += "### ä½¿ç”¨å»ºè®®\n\n"
        content += "1. å…ˆé˜…è¯»è‡ªåŠ¨è¯„ä¼°æŠ¥å‘Šï¼Œäº†è§£å„æ¨¡å‹çš„åˆæ­¥è¡¨ç°\n"
        content += "2. é‡ç‚¹å…³æ³¨ã€Œç½®ä¿¡åº¦ï¼šä½ã€çš„è€ƒå¯Ÿç‚¹ï¼Œè¿›è¡Œäººå·¥å¤æ ¸\n"
        content += "3. åœ¨ã€Œäººå·¥è°ƒæ•´åŒºåŸŸã€å¡«å†™ä¿®æ­£åçš„åˆ†æ•°å’Œç†ç”±\n"
        content += "4. ç»“åˆè‡ªåŠ¨è¯„åˆ†å’Œäººå·¥è¯„åˆ†ï¼Œå¾—å‡ºæœ€ç»ˆç»“è®º\n"
        content += "5. å°†æœ¬æŠ¥å‘Šç”¨äºç¬”è¯•ç­”æ¡ˆçš„æ’°å†™\n\n"
        
        content += "---\n\n"
        content += f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}  \n"
        content += "**è¯„ä¼°ç³»ç»Ÿç‰ˆæœ¬**: ä¸‰ç»´åº¦å…«è€ƒå¯Ÿç‚¹ v1.0\n\n"
        
        return content
    
    def generate_simple_summary(self, test_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆç®€å•çš„æ§åˆ¶å°è¾“å‡ºæ‘˜è¦"""
        summary = "\n" + "="*60 + "\n"
        summary += "ğŸ“Š æµ‹è¯•å®Œæˆï¼è¯„ä¼°æ‘˜è¦\n"
        summary += "="*60 + "\n\n"
        
        for model_name, results in test_results.items():
            if not results:
                continue
            
            evaluations = [r['evaluation'] for r in results.values() if 'evaluation' in r and r['evaluation']]
            if evaluations:
                avg_score = sum(e['total_score_100'] for e in evaluations) / len(evaluations)
                summary += f"ğŸ¤– {model_name}: å¹³å‡å¾—åˆ† {avg_score:.1f}/100\n"
        
        summary += "\n" + "="*60 + "\n"
        return summary
