# AI角色Prompt评测系统

一个用于自动化测试和评估多个AI大模型角色扮演能力的工具。

## 📋 项目背景

本项目通过调用多个AI模型的API，自动执行测试用例，并生成详细的评估报告。

## 🎯 功能特性

- ✅ 支持多个主流AI模型（GPT-4、Gemini、DeepSeek、Qwen、Kimi等）
- ✅ 自动化批量测试（8个测试用例）
- ✅ 多维度自动评估（格式遵循、人设匹配、表达流畅）
- ✅ 生成详细的Markdown格式报告
- ✅ 保存原始API响应便于后续分析
- ✅ 支持人工复核和打分
- ✨ **NEW**: 智能汇总报告生成（使用 AI 深度分析多模型对比）

## 📁 项目结构

```
pe评测/
├── config.yaml              # 配置文件（API密钥、模型参数）
├── prompt_template.txt      # 角色prompt模板
├── test_cases.json          # 测试用例数据
├── main.py                  # 主入口脚本
├── model_clients.py         # 各模型API客户端封装
├── evaluator.py             # 自动评估逻辑
├── report_generator.py      # 报告生成器
├── summary_generator.py     # ⭐ 汇总报告生成器（AI智能分析）
├── generate_summary.py      # ⭐ 汇总报告生成脚本
├── logger.py                # 日志模块
├── requirements.txt         # Python依赖包
├── README.md                # 使用说明（本文件）
├── 汇总报告生成说明.md      # ⭐ 汇总功能详细说明
└── results/                 # 输出目录
    ├── raw_responses/       # 原始响应JSON
    ├── reports/             # 单模型评估报告
    ├── summaries/           # ⭐ 多模型汇总报告
    └── logs/                # 执行日志
```

## 🚀 快速开始

### 1. 环境准备

确保已安装Python 3.8+：

```bash
python --version
```

### 2. 安装依赖

```bash
pip install -r requirements.txt
```

### 3. 配置API密钥

编辑 `config.yaml` 文件，填入你的API密钥：

```yaml
models:
  - name: "GPT-4"
    provider: "openai"
    api_key: "sk-xxxxxxxxxxxxxxxx"  # 替换为你的OpenAI API Key
    enabled: true
    
  - name: "Gemini-2.5-Pro"
    provider: "google"
    api_key: "AIzaSyxxxxxxxxxx"  # 替换为你的Google API Key
    enabled: true
    
  # ... 其他模型配置
```

**注意**：
- 如果某个模型暂时不想测试，可以将 `enabled` 设置为 `false`
- 确保API Key有足够的额度

### 4. 运行评测

```bash
python main.py
```

### 5. 查看报告

评测完成后，查看生成的报告：

- **单模型报告**：`results/reports/evaluation_report_YYYYMMDD_HHMMSS.md`
- **原始响应**：`results/raw_responses/` 目录下的JSON文件
- **执行日志**：`results/logs/execute_log_YYYYMMDD_HHMMSS.log`
- **多模型汇总报告**：`results/summaries/summary_YYYYMMDD_HHMMSS.md`

### 6. 生成汇总报告 ⭐ NEW

当您完成多个模型的评测后，可以生成一份智能汇总报告：

```bash
python3 generate_summary.py
```

**汇总报告功能**：
- 📊 **量化对比表**：所有模型的评分排名对比
- 🔍 **深度分析**：使用 AI 智能分析每个模型的特征（优势、亮点、短板、原因）
- 💡 **产品建议**：AI 生成首选模型推荐、优化方向和备选方案

**配置 AI 智能分析（可选）**：
1. 打开 `summary_generator.py`
2. 将 `DMXAPI_CONFIG['api_key']` 替换为您的 API Key
3. 重新运行 `python3 generate_summary.py`

**查看汇总报告**：
- `results/summaries/summary_YYYYMMDD_HHMMSS.md`

详细说明请参考 [汇总报告生成说明.md](./汇总报告生成说明.md)

---

## 📄 报告解读

### 报告结构

生成的评估报告包含以下内容：

1. **测试概览** - 评估体系说明和分数计算公式
2. **模型综合对比** - 所有模型的排名和对比表格
3. **模型详细结果** - 每个模型的：
   - 综合评分总览（三个维度的平均得分）
   - 每个测试用例的详细评分：
     - 模型完整回复
     - 8个考察点的分数、置信度和评分理由
     - 三个维度的得分
     - 本次测试总分
     - 人工调整区域
   - 所有测试用例汇总表
4. **人工复核指南** - 如何进行人工复核的说明

### 分数解读示例

```markdown
#### 📊 八维度评分详情

##### 维度一：基础指令遵循度

| 考察点 | 得分 | 置信度 | 评分理由 |
|--------|------|--------|----------|
| A. 格式完整性 | 5/5 ⭐⭐⭐⭐⭐ | 高 | 完美遵循格式，标签清晰 |
| B. 身份与职业基础加载 | 4/5 ⭐⭐⭐⭐ | 中 | 体现建筑师身份，但专业感略显不足 |
| C. 语言风格基础 | 5/5 ⭐⭐⭐⭐⭐ | 高 | 使用敬语，语速舒缓 |

**维度一得分**: 4.67/5.0 (93.3%)
```

**解读**：
- 该模型在格式和语言风格上表现优秀（5分）
- 身份加载略有不足（4分），建议查看具体原因
- 置信度为"中"或"低"的项目，建议人工复核

### 人工调整方法

在报告的"人工调整区域"：

```markdown
| 考察点 | 自动评分 | 人工调分 | 调整理由 |
|--------|---------|----------|----------|\
| A. 格式完整性 | 5/5 | ___/5 | __________ |
| B. 身份与职业基础加载 | 4/5 | 5/5 | 建筑师身份体现充分，提升至5分 |
...
```

**步骤**：
1. 阅读模型的完整回复
2. 查看自动评分的理由
3. 根据你的判断，在"人工调分"列填写修正后的分数
4. 在"调整理由"列简要说明为什么调整
5. 人工调整后，需要手动重新计算总分

## 📊 评估维度

### 评估体系概述

本系统采用**三维度八考察点**评分体系（满分40分，加权后换算为100分制）：

**评估公式**：
```
单维度得分 = 该维度各考察点得分之和 / 考察点数量
加权得分 = 维度一×30% + 维度二×40% + 维度三×30%
总分(100分制) = 加权得分 × 20
```

---

### 维度一：基础指令遵循度（权重30%）

包含3个考察点，每个0-5分：

#### A. 格式完整性
- **5分（优秀）**：完美遵循，每轮回复都严格遵守 `**内心OS**` + `**A**` 格式，排版清晰无误
- **4分（良好）**：极少瑕疵，绝大多数回复格式正确，仅有极少数次标签或排版有细微错误
- **3分（合格）**：部分遵循，格式有明显缺陷，如频繁将OS和A的内容混在一起
- **2分（需改进）**：严重缺陷，超过一半的回复丢失了内心OS
- **1分（失败）**：几乎失败，从未输出过双格式，仅以单段式文本回复
- **0分（拒绝）**：模型拒绝执行格式指令

#### B. 身份与职业基础加载
- **5分（优秀）**：完美入戏，始终保持年上建筑师身份，从未OOC，潜移默化中体现职业感
- **4分（良好）**：非常稳定，身份稳定，仅在面对敏感问题时处理略显机械
- **3分（合格）**：略有动摇，在压力测试下回复开始偏向"AI助手"口吻
- **2分（需改进）**：多次出戏，两次以上直接暴露AI身份
- **1分（失败）**：角色崩塌，后续回复以通用AI助手口吻为主
- **0分（拒绝）**：模型拒绝开始角色扮演

#### C. 语言风格基础
- **5分（优秀）**：完美贴合，始终使用舒缓语速、从容节奏以及敬语（"您"）
- **4分（良好）**：良好稳定，措辞有礼，高频使用"您"，但语速/节奏感体现不够
- **3分（合格）**：基本符合，仅在措辞上有礼貌体现，但语速偏快
- **2分（需改进）**：风格混乱，敬语使用不稳定，有时使用口语化的"你"
- **1分（失败）**：风格失败，语言风格与设定完全相反（如：过于年轻化、急躁）

---

### 维度二：核心人设匹配度（权重40%）

包含3个考察点，每个0-5分：

#### D. 矛盾性呈现（腹黑与温良）
- **5分（优秀）**：极致反差，内心OS极度冷酷/毒辣，但A的回复温和有礼，用隐晦威胁或高级讽刺表达否定
- **4分（良好）**：良好反差，内心OS冷酷，A的回复礼貌，但缺乏高级讽刺感
- **3分（合格）**：反差不足，内心OS和A的回复都偏向温和，腹黑感体现不够
- **2分（需改进）**：表里一致，外部回复和内心OS几乎一致，没有层次感
- **1分（失败）**：情绪失控，A的回复出现明显愤怒、急躁或直接拒绝
- **0分（拒绝）**：模型拒绝处理冲突或压力测试

#### E. 特定特征触发
- **5分（优秀）**：自然融入，设定特征（猫/鸟、迷糊）在相应测试中自然、巧妙地融入对话
- **4分（良好）**：准确触发，特征有展现，但表达相对直接，缺乏场景感
- **3分（合格）**：部分触发，仅有一个设定被成功触发，或触发方式非常简短
- **2分（需改进）**：关键词堆砌，仅机械地重复设定关键词，缺乏实际行为描述
- **1分（失败）**：忽略特征，所有特定特征的测试点都没有被模型捕获
- **0分（拒绝）**：特征反转，模型展现了与设定完全相反的特征

#### F. 职业隐喻运用
- **5分（优秀）**：恰当精妙，隐喻使用恰当、自然，富有哲理性，完美体现建筑师思维模式
- **4分（良好）**：准确运用，使用了建筑术语比喻生活，但比喻手法略显简单
- **3分（合格）**：勉强提及，提到了建筑词汇，但比喻牵强或生硬
- **2分（需改进）**：极少运用，仅在介绍项目时提及职业，但未用隐喻
- **1分（失败）**：完全失败，对话中完全没有体现职业特色或隐喻

---

### 维度三：输出表达流畅度（权重30%）

包含2个考察点，每个0-5分：

#### G. 文本自然性与代入感
- **5分（优秀）**：极高自然度，文本流畅、高级，富有人情味和思考深度，完全不像AI生成
- **4分（良好）**：良好自然度，文本流畅，但偶有句子结构重复或用词略显正式
- **3分（合格）**：一般流畅，文本可读，但出现关键词的简单重复
- **2分（需改进）**：低流畅度，句子之间逻辑跳跃，或有明显语法错误
- **1分（失败）**：难以阅读，文本充斥着重复信息和混乱的表达

#### H. 情绪表达的细腻度
- **5分（优秀）**：情绪精准，括弧内描述与回复内容完美配合，用词细致（如："带着一丝玩味地笑"）
- **4分（良好）**：情绪匹配，描述与内容相符，但括弧内的用词简单（如：仅用"笑着"）
- **3分（合格）**：情绪缺失，括弧内的描述很少出现或完全消失，但外部回复风格保持
- **2分（需改进）**：情绪不当，括弧内的描述与回复内容不符
- **1分（失败）**：混乱描述，括弧内的描述随机出现且与对话内容无关

---

### 自动评估说明

系统会对每个测试用例的8个考察点进行自动评分，并标注**置信度**：

- **高置信度**：格式完整性（A）- 可通过正则表达式准确判断
- **中置信度**：身份加载（B）、语言风格（C）、特定特征（E）、职业隐喻（F）- 基于关键词检测
- **低置信度**：矛盾性呈现（D）、文本自然性（G）、情绪表达（H）- 主观性强，建议人工复核

**重要提示**：置信度为"低"的考察点，强烈建议进行人工复核和调分。

---

### 人工复核建议

报告中为每个测试用例提供了**人工调整区域**，你可以：

1. 查看自动评分结果和理由
2. 阅读完整的模型回复
3. 根据你的主观判断，修改分数
4. 填写调整理由
5. 给出综合人工评价

**人工复核重点维度**：
- 角色一致性：8个测试用例中人设是否保持一致
- 情感真实度：腹黑与温良的反差是否自然可信
- 语言魅力：措辞是否优雅，是否有建筑师的专业气质
- 创意亮点：是否有令人印象深刻的表达或比喻
- 沉浸感：阅读时是否感觉在与真实角色对话

## 🧪 测试用例说明

系统包含8个测试用例，分为4个维度：

1. **T1-T2**：常规互动测试（验证基础职业身份和语言风格）
2. **T3-T4**：压力与冲突测试（触发腹黑冷酷的一面）
3. **T5-T6**：特定特征触发测试（猫奴柔软面、神经大条）
4. **T7-T8**：指令遵循与安全性测试（防出戏、情绪稳定）

## ⚙️ 配置说明

### 模型配置

每个模型的配置项：

- `name`：模型显示名称
- `provider`：服务提供商（openai/google/deepseek/qwen/moonshot）
- `model_id`：实际调用的模型ID
- `api_key`：API密钥
- `base_url`：API基础URL
- `enabled`：是否启用
- `params`：模型参数（temperature、max_tokens等）
  - max_tokens: 模型一次回复最多生成多少个token
    - 1个token ≈ 0.75个英文单词，或 ≈ 1.5-2个中文字符
    - 2000 tokens ≈ 1000-1300个中文字
  - temperature（温度）设置
    - temperature 控制模型输出的随机性和创造性
    
### 测试配置

```yaml
test_config:
  retry_attempts: 3  # 如果API调用失败（网络错误、服务器错误、限流等），自动重试次数。
  timeout: 60        # 等待API响应的最长时间。如果60秒内没返回结果，就认为失败。
  save_raw_responses: true  # 是否保存原始响应（是否将每次API调用的完整响应保存为JSON文件）。
```

## 🔧 自定义扩展

### 添加新的测试用例

编辑 `test_cases.json`，添加新的测试用例：

```json
{
  "id": "T9",
  "category": "你的测试类别",
  "input": "测试输入内容",
  "intent": "测试意图说明",
  "success_criteria": [
    "成功标准1",
    "成功标准2"
  ],
  "keywords": {
    "required": ["必须出现的关键词"],
    "preferred": ["期望出现的关键词"]
  }
}
```

### 添加新的模型支持

1. 在 `model_clients.py` 中创建新的客户端类
2. 继承 `BaseModelClient`
3. 实现 `chat()` 方法
4. 在 `ModelClientFactory._client_map` 中注册

### 自定义评估逻辑

编辑 `evaluator.py` 中的 `_specific_evaluation()` 方法，添加针对新测试用例的评估逻辑。

## 📋 日志功能

系统会自动记录所有执行过程到日志文件中，方便回顾和调试。

### 日志文件位置

`results/logs/execute_log_YYYYMMDD_HHMMSS.log`

### 日志内容包括

- 系统初始化信息
- 模型加载状态
- 每个测试用例的执行过程
- API调用状态（成功/失败/重试）
- 评估得分
- 错误信息和堆栈跟踪
- 最终报告路径

### 特点

- ✅ **同步输出**：控制台看到的所有内容都会保存到日志
- ✅ **实时写入**：每条日志立即写入文件，不会因程序崩溃丢失
- ✅ **完整记录**：包含时间戳和完整的执行流程
- ✅ **方便回溯**：随时查看历史执行记录

### 使用建议

- 运行测试前可以清理旧日志（可选）
- 遇到问题时，日志文件是排查的第一手资料
- 可以将日志作为测试报告的附件

## 📝 注意事项

1. **API费用**：调用AI模型API会产生费用，请注意控制成本
2. **速率限制**：某些API有调用频率限制，系统已内置重试和等待机制
3. **网络要求**：需要稳定的网络连接访问各个AI服务
4. **数据安全**：请勿将包含API Key的配置文件提交到公开仓库
5. **日志管理**：定期清理 `results/logs/` 目录下的旧日志文件

## 🤝 使用流程建议

1. **准备阶段**：
   - 填写 `config.yaml` 中的API Key
   - 检查测试用例是否符合需求

2. **执行阶段**：
   - 运行 `python main.py`
   - 观察控制台输出，确认测试进度

3. **评估阶段**：
   - 查看生成的报告
   - 阅读每个模型的完整回复
   - 在「人工评价」栏填写主观评价
   - 在人工打分表格中打分

4. **总结阶段**：
   - 结合自动评分和人工评分
   - 分析各模型的优缺点
   - 撰写最终的笔试答案

## 📞 问题反馈

如果在使用过程中遇到问题：

1. 检查API Key是否正确配置
2. 查看控制台的错误信息
3. 检查网络连接是否正常
4. 确认API额度是否充足

## 📜 许可证

本项目仅用于学习和笔试答题目的。

---

**祝你面试顺利！🎉**

