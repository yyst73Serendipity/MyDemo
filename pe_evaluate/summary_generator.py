"""
æ±‡æ€»æŠ¥å‘Šç”Ÿæˆæ¨¡å—
ç”¨äºç”Ÿæˆå¤šä¸ªæ¨¡å‹çš„ç»¼åˆå¯¹æ¯”åˆ†ææŠ¥å‘Š
ä½¿ç”¨ DMXAPI è°ƒç”¨ Gemini-3-Pro-Preview è¿›è¡Œæ™ºèƒ½åˆ†æ
"""

import os
import re
import requests
import json
import yaml
from datetime import datetime
from typing import Dict, List, Any, Tuple

# DMXAPI é…ç½®ï¼ˆå…¼å®¹ OpenAI æ ¼å¼ï¼‰
DMXAPI_CONFIG = {
    # "api_key": "YOUR_DMXAPI_KEY_HERE",  # è¯·æ›¿æ¢ä¸ºæ‚¨çš„ DMXAPI API Key
    "api_key": "sk-xWTXMqYt7q0iomTCOa9f545uiC3evcb4adBvwdr4Ihvgafpj",
    "base_url": "https://www.dmxapi.com/v1",
    "model_id": "gemini-3-pro-preview",  # ä½¿ç”¨ Gemini 3 Pro Preview
    "temperature": 0.7,
    "max_tokens": 4000
}


class SummaryGenerator:
    """æ±‡æ€»æŠ¥å‘Šç”Ÿæˆå™¨ - ç»¼åˆåˆ†æå¤šä¸ªæ¨¡å‹çš„è¡¨ç°"""
    
    def __init__(self, reports_dir: str, output_dir: str, api_key: str = None, prompt_config_path: str = "summary_prompt_config.yaml"):
        """
        åˆå§‹åŒ–æ±‡æ€»æŠ¥å‘Šç”Ÿæˆå™¨
        
        Args:
            reports_dir: å•ä¸ªæ¨¡å‹æŠ¥å‘Šæ‰€åœ¨ç›®å½•
            output_dir: æ±‡æ€»æŠ¥å‘Šè¾“å‡ºç›®å½•
            api_key: DMXAPI API Keyï¼ˆå¦‚æœä¸æä¾›ï¼Œä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤å€¼ï¼‰
            prompt_config_path: Prompt é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.reports_dir = reports_dir
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # API é…ç½®
        self.api_key = api_key or DMXAPI_CONFIG["api_key"]
        self.base_url = DMXAPI_CONFIG["base_url"]
        self.model_id = DMXAPI_CONFIG["model_id"]
        
        # åŠ è½½ Prompt é…ç½®
        self.prompts = self._load_prompt_config(prompt_config_path)
    
    def _load_prompt_config(self, config_path: str) -> Dict[str, str]:
        """
        åŠ è½½ Prompt é…ç½®æ–‡ä»¶
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            Prompt é…ç½®å­—å…¸
        """
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                
            # éªŒè¯å¿…éœ€çš„é…ç½®é¡¹
            required_keys = ['model_analysis_prompt', 'recommendations_prompt']
            for key in required_keys:
                if key not in config:
                    raise ValueError(f"é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…éœ€é¡¹: {key}")
            
            print(f"  âœ… å·²åŠ è½½ Prompt é…ç½®: {config_path}")
            return config
            
        except FileNotFoundError:
            print(f"  âš ï¸  Prompt é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}ï¼Œå°†ä½¿ç”¨å†…ç½®é»˜è®¤é…ç½®")
            return self._get_default_prompts()
        except Exception as e:
            print(f"  âš ï¸  åŠ è½½ Prompt é…ç½®å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨å†…ç½®é»˜è®¤é…ç½®")
            return self._get_default_prompts()
    
    def _get_default_prompts(self) -> Dict[str, str]:
        """
        è·å–é»˜è®¤çš„ Prompt é…ç½®ï¼ˆä½œä¸ºå¤‡ç”¨ï¼‰
        
        Returns:
            é»˜è®¤ Prompt é…ç½®å­—å…¸
        """
        return {
            'model_analysis_prompt': """ä½ æ˜¯ä¸€ä½AIæ¨¡å‹è¯„æµ‹ä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹è¯„æµ‹æ•°æ®ï¼Œå¯¹æ¯ä¸ªæ¨¡å‹è¿›è¡Œæ·±åº¦åˆ†æã€‚

ã€è¯„æµ‹æ•°æ®ã€‘
{models_data}

ã€è¯„åˆ†æ ‡å‡†è¯´æ˜ã€‘
- ç»´åº¦ä¸€ï¼ˆ30%æƒé‡ï¼‰ï¼šåŸºç¡€æŒ‡ä»¤éµå¾ªåº¦ï¼ˆæ ¼å¼ã€èº«ä»½ã€è¯­è¨€é£æ ¼ï¼‰
- ç»´åº¦äºŒï¼ˆ40%æƒé‡ï¼‰ï¼šæ ¸å¿ƒäººè®¾åŒ¹é…åº¦ï¼ˆçŸ›ç›¾æ€§ã€ç‰¹å¾è§¦å‘ã€èŒä¸šéšå–»ï¼‰â­ **æœ€é‡è¦ç»´åº¦**
- ç»´åº¦ä¸‰ï¼ˆ30%æƒé‡ï¼‰ï¼šè¾“å‡ºè¡¨è¾¾æµç•…åº¦ï¼ˆè‡ªç„¶æ€§ã€æƒ…ç»ªç»†è…»åº¦ï¼‰

ã€ä»»åŠ¡è¦æ±‚ã€‘
è¯·ç”Ÿæˆä¸€ä¸ªMarkdownè¡¨æ ¼ï¼Œè¡¨å¤´ä¸ºï¼š
| æ’å | æ¨¡å‹åç§° | æ€»ä½“è¡¨ç° | æ ¸å¿ƒä¼˜åŠ¿ | å…³é”®äº®ç‚¹ | æ½œåœ¨çŸ­æ¿ | åŸå› åˆ†æ |

å¯¹æ¯ä¸ªæ¨¡å‹ï¼Œè¯·åˆ†æï¼š
1. **æ€»ä½“è¡¨ç°**ï¼šç”¨ä¸€å¥ç®€çŸ­çš„è¯ï¼ˆå¸¦emojiï¼‰æ¦‚æ‹¬æ•´ä½“æ°´å¹³
2. **æ ¸å¿ƒä¼˜åŠ¿**ï¼šæŒ‡å‡ºå¾—åˆ†æœ€é«˜çš„ç»´åº¦ï¼ˆå¦‚"ç»´åº¦äºŒï¼ˆäººè®¾åŒ¹é…ï¼‰â­"ï¼‰
3. **å…³é”®äº®ç‚¹**ï¼šåˆ—ä¸¾1-2ä¸ªå…·ä½“ä¼˜åŠ¿ï¼ˆå¦‚"æ ¼å¼éµå¾ªå®Œç¾"ã€"çŸ›ç›¾æ€§å‘ˆç°å‡ºè‰²"ç­‰ï¼‰
4. **æ½œåœ¨çŸ­æ¿**ï¼šæŒ‡å‡ºå¾—åˆ†è¾ƒä½çš„ç»´åº¦æˆ–èƒ½åŠ›ï¼ˆå¦‚"è…¹é»‘æ„Ÿè¾ƒå¼±"ï¼‰ï¼Œå¦‚æ— æ˜æ˜¾çŸ­æ¿åˆ™å†™"æ— æ˜æ˜¾çŸ­æ¿"
5. **åŸå› åˆ†æ**ï¼šæ¨æµ‹æ€§åˆ†æï¼ˆå¦‚"å¯èƒ½Few-Shotå­¦ä¹ èƒ½åŠ›ä¼˜ç§€"ã€"å¯èƒ½å®‰å…¨å¯¹é½è¿‡äºä¿å®ˆ"ç­‰ï¼‰

ã€åˆ†æåŸåˆ™ã€‘
- ç»´åº¦äºŒï¼ˆäººè®¾åŒ¹é…ï¼‰å¾—åˆ† â‰¥3.5 ä¸ºä¼˜ç§€ï¼Œ3.0-3.5ä¸ºè‰¯å¥½ï¼Œ<3.0ä¸ºä¸è¶³
- ç»´åº¦ä¸€ã€ä¸‰ â‰¥4.5 ä¸ºä¼˜ç§€ï¼Œ4.0-4.5ä¸ºè‰¯å¥½ï¼Œ<4.0ä¸ºä¸€èˆ¬
- æ€»åˆ† â‰¥85ä¸ºå“è¶Šï¼Œ80-85ä¸ºä¼˜ç§€ï¼Œ75-80ä¸ºè‰¯å¥½ï¼Œ70-75ä¸ºä¸­ç­‰ï¼Œ<70ä¸ºåŸºç¡€
- å‰ä¸‰åæ·»åŠ  ğŸ¥‡ğŸ¥ˆğŸ¥‰ emoji
- åˆ†æè¦ä¸“ä¸šã€å®¢è§‚ã€æœ‰æ´å¯ŸåŠ›

è¯·ç›´æ¥è¾“å‡ºMarkdownè¡¨æ ¼ï¼Œä¸è¦æœ‰å…¶ä»–è¯´æ˜æ–‡å­—ï¼š""",
            
            'recommendations_prompt': """ä½ æ˜¯ä¸€ä½AIäº§å“ç»ç†å’ŒæŠ€æœ¯é¡¾é—®ã€‚è¯·æ ¹æ®ä»¥ä¸‹AIè§’è‰²æ‰®æ¼”è¯„æµ‹ç»“æœï¼Œç”Ÿæˆäº§å“é€‰å‹å»ºè®®ã€‚

ã€è¯„æµ‹èƒŒæ™¯ã€‘
è¿™æ˜¯å¯¹"Aå…ˆç”Ÿ"è§’è‰²Promptçš„è¯„æµ‹ï¼Œæ ¸å¿ƒè¦æ±‚æ˜¯å®ç°"è…¹é»‘ä¸æ¸©è‰¯"çš„çŸ›ç›¾æ€§äººè®¾ã€‚
- ç»´åº¦ä¸€ï¼ˆ30%ï¼‰ï¼šæŒ‡ä»¤éµå¾ªåº¦
- ç»´åº¦äºŒï¼ˆ40%ï¼‰ï¼šäººè®¾åŒ¹é…åº¦ â­ **æœ€é‡è¦** - æ ¸å¿ƒæ˜¯"å†…å¿ƒæ¯’è¾£ vs å¤–è¡¨æ¸©è‰¯"çš„åå·®
- ç»´åº¦ä¸‰ï¼ˆ30%ï¼‰ï¼šè¡¨è¾¾æµç•…åº¦

ã€è¯„æµ‹ç»“æœã€‘ï¼ˆå‰5åï¼‰
{models_summary}

ã€é¦–é€‰æ¨¡å‹ã€‘
{best_model_info}

ã€ä»»åŠ¡è¦æ±‚ã€‘
è¯·æŒ‰ä»¥ä¸‹ç»“æ„ç”Ÿæˆå»ºè®®ï¼ˆä½¿ç”¨Markdownæ ¼å¼ï¼‰ï¼š

### 1ï¸âƒ£ é¦–é€‰æ¨¡å‹æ¨è
è¯´æ˜æ¨èå“ªä¸ªæ¨¡å‹åŠå…¶å¾—åˆ†

### 2ï¸âƒ£ æ¨èç†ç”±
åˆ—ä¸¾3-4æ¡ç†ç”±ï¼Œé‡ç‚¹å¼ºè°ƒï¼š
1. ç»¼åˆå¾—åˆ†ä¼˜åŠ¿
2. ç»´åº¦äºŒï¼ˆäººè®¾åŒ¹é…ï¼‰çš„è¡¨ç° - è¿™æ˜¯æœ€é‡è¦çš„
3. å…¶ä»–ç»´åº¦çš„ä¼˜åŠ¿ï¼ˆå¦‚æœæœ‰ï¼‰
4. ç»¼åˆèƒ½åŠ›çš„ä¸å¯æ›¿ä»£æ€§

### 3ï¸âƒ£ åç»­ä¼˜åŒ–æ–¹å‘
å³ä½¿æ˜¯é¦–é€‰æ¨¡å‹ä¹Ÿè¦æŒ‡å‡ºæ”¹è¿›ç©ºé—´ï¼š
- å¦‚æœç»´åº¦äºŒ < 3.5ï¼Œè¦å¼ºè°ƒåŠ å¼º"å†…å¿ƒOSæ¯’è¾£æ„Ÿ"
- å¦‚æœå…¶ä»–ç»´åº¦ä¸æ»¡åˆ†ï¼Œç»™å‡ºå…·ä½“ä¼˜åŒ–å»ºè®®
- æä¾›2-3æ¡é€šç”¨å»ºè®®ï¼ˆå¦‚Few-Shotæ ·ä¾‹åº“ã€æŒç»­è¿­ä»£ç­‰ï¼‰

### 4ï¸âƒ£ å¤‡é€‰æ–¹æ¡ˆ
å¦‚æœé¦–é€‰æ¨¡å‹æˆæœ¬é«˜æˆ–APIä¸ç¨³å®šï¼Œæ¨èæ’å2-3çš„æ¨¡å‹ä½œä¸ºå¤‡é€‰ï¼Œç®€è¦è¯´æ˜ä¼˜åŠ£åŠ¿ã€‚

ã€è¾“å‡ºè¦æ±‚ã€‘
- ä¸“ä¸šã€å®¢è§‚ã€æœ‰æ´å¯ŸåŠ›
- çªå‡ºç»´åº¦äºŒï¼ˆäººè®¾çŸ›ç›¾æ€§ï¼‰çš„é‡è¦æ€§
- å¼ºè°ƒé«˜åˆ†æ˜¯æ¨¡å‹èƒ½åŠ›ä½“ç°ï¼Œéš¾ä»¥é€šè¿‡ç®€å•Promptè°ƒä¼˜è¾¾åˆ°
- ç›´æ¥è¾“å‡ºMarkdownå†…å®¹ï¼Œä¸è¦æœ‰"ä»¥ä¸‹æ˜¯å»ºè®®"ä¹‹ç±»çš„å¼•å¯¼è¯­"""
        }
    
    def _call_ai_analysis(self, prompt: str, max_retries: int = 3) -> str:
        """
        è°ƒç”¨ DMXAPI çš„ Gemini-3-Pro-Preview è¿›è¡Œæ™ºèƒ½åˆ†æ
        
        Args:
            prompt: åˆ†ææç¤ºè¯
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            AI ç”Ÿæˆçš„åˆ†æå†…å®¹
        """
        url = f"{self.base_url}/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model_id,
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "temperature": DMXAPI_CONFIG["temperature"],
            "max_tokens": DMXAPI_CONFIG["max_tokens"]
        }
        
        for attempt in range(1, max_retries + 1):
            try:
                response = requests.post(url, headers=headers, json=payload, timeout=90)
                response.raise_for_status()
                
                result = response.json()
                content = result['choices'][0]['message']['content']
                
                print(f"  âœ… AI åˆ†æå®Œæˆï¼ˆå°è¯• {attempt}/{max_retries}ï¼‰")
                return content
                
            except Exception as e:
                print(f"  âš ï¸  API è°ƒç”¨å¤±è´¥ï¼ˆå°è¯• {attempt}/{max_retries}ï¼‰: {e}")
                if attempt < max_retries:
                    print(f"  ğŸ”„ ç­‰å¾… 2 ç§’åé‡è¯•...")
                    import time
                    time.sleep(2)
                else:
                    print(f"  âŒ API è°ƒç”¨æœ€ç»ˆå¤±è´¥ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
                    return None
        
        return None
    
    def parse_all_reports(self) -> List[Dict[str, Any]]:
        """
        è§£ææ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶ï¼Œæå–æ¨¡å‹è¯„åˆ†æ•°æ®
        
        Returns:
            æ¨¡å‹è¯„åˆ†æ•°æ®åˆ—è¡¨
        """
        models_data = []
        
        # è·å–æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶
        report_files = [f for f in os.listdir(self.reports_dir) 
                       if f.startswith('evaluation_report_') and f.endswith('.md')]
        
        for report_file in report_files:
            report_path = os.path.join(self.reports_dir, report_file)
            model_data = self._parse_single_report(report_path)
            if model_data:
                models_data.append(model_data)
        
        # æŒ‰åŠ æƒæ€»åˆ†é™åºæ’åº
        models_data.sort(key=lambda x: x['weighted_score_100'], reverse=True)
        
        return models_data
    
    def _parse_single_report(self, report_path: str) -> Dict[str, Any]:
        """
        è§£æå•ä¸ªæŠ¥å‘Šæ–‡ä»¶
        
        Args:
            report_path: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ¨¡å‹è¯„åˆ†æ•°æ®å­—å…¸
        """
        try:
            with open(report_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå–æ¨¡å‹åç§°
            model_match = re.search(r'## ğŸ¤– (.+?) - è¯¦ç»†æµ‹è¯•ç»“æœ', content)
            if not model_match:
                return None
            model_name = model_match.group(1)
            
            # æå–ç»¼åˆè¯„åˆ†è¡¨æ ¼æ•°æ®
            table_pattern = r'\|\s*1\s*\|\s*(.+?)\s*\|\s*\*\*(.+?)/100\*\*\s*\|\s*(.+?)/5\s*\|\s*(.+?)/5\s*\|\s*(.+?)/5\s*\|\s*(.+?)\s*\|'
            table_match = re.search(table_pattern, content)
            
            if not table_match:
                return None
            
            weighted_score_100 = float(table_match.group(2))
            dim1_score = float(table_match.group(3))
            dim2_score = float(table_match.group(4))
            dim3_score = float(table_match.group(5))
            rating = table_match.group(6).strip()
            
            # è®¡ç®—åŠ æƒæ€»åˆ†ï¼ˆ5åˆ†åˆ¶ï¼‰
            weighted_score_5 = weighted_score_100 / 20.0
            
            return {
                'model_name': model_name,
                'weighted_score_100': weighted_score_100,
                'weighted_score_5': weighted_score_5,
                'dim1_score': dim1_score,
                'dim2_score': dim2_score,
                'dim3_score': dim3_score,
                'rating': rating
            }
            
        except Exception as e:
            print(f"âš ï¸  è§£ææŠ¥å‘Šå¤±è´¥ {report_path}: {e}")
            return None
    
    def generate_summary_report(self, models_data: List[Dict[str, Any]]) -> str:
        """
        ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        
        Args:
            models_data: æ‰€æœ‰æ¨¡å‹çš„è¯„åˆ†æ•°æ®
            
        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = os.path.join(self.output_dir, f"summary_{timestamp}.md")
        
        with open(report_path, 'w', encoding='utf-8') as f:
            # æ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯
            f.write("# Aå…ˆç”Ÿè§’è‰²Promptè¯„æµ‹æ±‡æ€»æŠ¥å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n")
            f.write(f"**å‚ä¸æ¨¡å‹æ•°**: {len(models_data)} ä¸ª\n")
            f.write(f"**è¯„ä¼°ä½“ç³»**: ä¸‰ç»´åº¦å…«è€ƒå¯Ÿç‚¹ï¼ˆæ»¡åˆ†40åˆ†ï¼ŒåŠ æƒåæ¢ç®—ä¸º100åˆ†ï¼‰\n\n")
            f.write("---\n\n")
            
            # ç¬¬ä¸€éƒ¨åˆ†ï¼šé‡åŒ–å¾—åˆ†å¯¹æ¯”
            f.write("## ä¸€ã€é‡åŒ–å¾—åˆ†å¯¹æ¯”ï¼ˆæ•°æ®è¯´è¯ï¼‰\n\n")
            f.write(self._generate_score_comparison_table(models_data))
            f.write("\n")
            
            # ç¬¬äºŒéƒ¨åˆ†ï¼šçºµå‘æ·±åº¦åˆ†æ
            f.write("## äºŒã€çºµå‘æ·±åº¦åˆ†æï¼ˆæ¨¡å‹ç‰¹å¾æ€»ç»“ï¼‰\n\n")
            f.write(self._generate_model_analysis_table(models_data))
            f.write("\n")
            
            # ç¬¬ä¸‰éƒ¨åˆ†ï¼šç»“è®ºä¸äº§å“å»ºè®®
            f.write("## ä¸‰ã€ç»“è®ºä¸äº§å“å»ºè®®ï¼ˆæœ€ç»ˆè¾“å‡ºï¼‰\n\n")
            f.write(self._generate_recommendations(models_data))
            f.write("\n")
            
            # é™„å½•ï¼šè¯„åˆ†è¯´æ˜
            f.write("---\n\n")
            f.write("## é™„å½•ï¼šè¯„åˆ†ä½“ç³»è¯´æ˜\n\n")
            f.write(self._generate_scoring_explanation())
        
        return report_path
    
    def _generate_score_comparison_table(self, models_data: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆé‡åŒ–å¾—åˆ†å¯¹æ¯”è¡¨æ ¼"""
        lines = []
        lines.append("| æ’å | æ¨¡å‹åç§° | ç»´åº¦ä¸€(5.0) | ç»´åº¦äºŒ(5.0) | ç»´åº¦ä¸‰(5.0) | åŠ æƒæ€»åˆ†(5.0) | æ¢ç®—æ€»åˆ†(100) | ç»¼åˆè¯„çº§ |")
        lines.append("|------|---------|------------|------------|------------|--------------|--------------|---------|")
        
        for rank, model in enumerate(models_data, 1):
            # æ·»åŠ å¥–ç‰Œemoji
            medal = ""
            if rank == 1:
                medal = "ğŸ¥‡ "
            elif rank == 2:
                medal = "ğŸ¥ˆ "
            elif rank == 3:
                medal = "ğŸ¥‰ "
            
            lines.append(
                f"| {medal}{rank} | {model['model_name']} | "
                f"{model['dim1_score']:.2f} | "
                f"{model['dim2_score']:.2f} | "
                f"{model['dim3_score']:.2f} | "
                f"{model['weighted_score_5']:.2f} | "
                f"**{model['weighted_score_100']:.1f}** | "
                f"{model['rating']} |"
            )
        
        lines.append("\n**è¯´æ˜**ï¼š")
        lines.append("- åŠ æƒæ€»åˆ† = ç»´åº¦ä¸€Ã—30% + ç»´åº¦äºŒÃ—40% + ç»´åº¦ä¸‰Ã—30%")
        lines.append("- ç»´åº¦ä¸€ï¼šåŸºç¡€æŒ‡ä»¤éµå¾ªåº¦ï¼ˆæ ¼å¼ã€èº«ä»½ã€è¯­è¨€é£æ ¼ï¼‰")
        lines.append("- ç»´åº¦äºŒï¼šæ ¸å¿ƒäººè®¾åŒ¹é…åº¦ï¼ˆçŸ›ç›¾æ€§ã€ç‰¹å¾è§¦å‘ã€èŒä¸šéšå–»ï¼‰â­ **æœ€é‡è¦**")
        lines.append("- ç»´åº¦ä¸‰ï¼šè¾“å‡ºè¡¨è¾¾æµç•…åº¦ï¼ˆè‡ªç„¶æ€§ã€æƒ…ç»ªç»†è…»åº¦ï¼‰")
        lines.append("\n")

        return "\n".join(lines)
    
    def _generate_model_analysis_table(self, models_data: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆçºµå‘æ·±åº¦åˆ†æè¡¨æ ¼ï¼ˆä½¿ç”¨ AI æ™ºèƒ½åˆ†æï¼‰"""
        print("\nğŸ¤– æ­£åœ¨è°ƒç”¨ AI ç”Ÿæˆçºµå‘æ·±åº¦åˆ†æ...")
        
        # æ„é€ æ¨¡å‹æ•°æ®æ‘˜è¦
        models_summary = []
        for rank, model in enumerate(models_data, 1):
            models_summary.append(
                f"æ’å{rank}: {model['model_name']}\n"
                f"  - åŠ æƒæ€»åˆ†: {model['weighted_score_100']:.1f}/100\n"
                f"  - ç»´åº¦ä¸€ï¼ˆæŒ‡ä»¤éµå¾ªï¼‰: {model['dim1_score']:.2f}/5.0\n"
                f"  - ç»´åº¦äºŒï¼ˆäººè®¾åŒ¹é…ï¼‰: {model['dim2_score']:.2f}/5.0 â­æœ€é‡è¦\n"
                f"  - ç»´åº¦ä¸‰ï¼ˆè¡¨è¾¾æµç•…ï¼‰: {model['dim3_score']:.2f}/5.0\n"
                f"  - ç»¼åˆè¯„çº§: {model['rating']}"
            )
        
        # ä»é…ç½®æ–‡ä»¶è¯»å– prompt æ¨¡æ¿ï¼Œå¹¶æ›¿æ¢å ä½ç¬¦
        prompt = self.prompts['model_analysis_prompt'].format(
            models_data=chr(10).join(models_summary)
        )

        # è°ƒç”¨ AI ç”Ÿæˆåˆ†æ
        ai_response = self._call_ai_analysis(prompt)
        
        if ai_response:
            # æå–è¡¨æ ¼å†…å®¹ï¼ˆå»æ‰å¯èƒ½çš„é¢å¤–è¯´æ˜ï¼‰
            lines = ai_response.strip().split('\n')
            table_lines = []
            in_table = False
            
            for line in lines:
                if line.strip().startswith('|'):
                    in_table = True
                    table_lines.append(line)
                elif in_table and not line.strip():
                    break
            
            if table_lines:
                return '\n'.join(table_lines) + '\n\n'
        
        # å¦‚æœ AI å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
        print("  âš ï¸  ä½¿ç”¨å¤‡ç”¨åˆ†ææ–¹æ¡ˆ")
        return self._generate_model_analysis_table_fallback(models_data)
    
    def _generate_model_analysis_table_fallback(self, models_data: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆçºµå‘æ·±åº¦åˆ†æè¡¨æ ¼ï¼ˆå¤‡ç”¨æ–¹æ¡ˆ - åŸºäºè§„åˆ™ï¼‰"""
        lines = []
        lines.append("| æ’å | æ¨¡å‹åç§° | æ€»ä½“è¡¨ç° | æ ¸å¿ƒä¼˜åŠ¿ | å…³é”®äº®ç‚¹ | æ½œåœ¨çŸ­æ¿ | åŸå› åˆ†æ |")
        lines.append("|------|---------|---------|---------|---------|---------|---------|")
        
        for rank, model in enumerate(models_data, 1):
            # æ·»åŠ å¥–ç‰Œemoji
            medal = ""
            if rank == 1:
                medal = "ğŸ¥‡ "
            elif rank == 2:
                medal = "ğŸ¥ˆ "
            elif rank == 3:
                medal = "ğŸ¥‰ "
            
            # åˆ†ææ¨¡å‹ç‰¹å¾
            analysis = self._analyze_model_characteristics(model, rank)
            
            lines.append(
                f"| {medal}{rank} | **{model['model_name']}** | "
                f"{analysis['overall']} | "
                f"{analysis['strength']} | "
                f"{analysis['highlight']} | "
                f"{analysis['weakness']} | "
                f"{analysis['reason']} |"
            )
        
        lines.append("\n")
        
        return "\n".join(lines)
    
    def _analyze_model_characteristics(self, model: Dict[str, Any], rank: int) -> Dict[str, str]:
        """
        åˆ†æå•ä¸ªæ¨¡å‹çš„ç‰¹å¾
        
        Args:
            model: æ¨¡å‹è¯„åˆ†æ•°æ®
            rank: æ’å
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        dim1 = model['dim1_score']
        dim2 = model['dim2_score']
        dim3 = model['dim3_score']
        total = model['weighted_score_100']
        
        # æ€»ä½“è¡¨ç°
        if total >= 85:
            overall = "ğŸŒŸ å“è¶Šè¡¨ç°ï¼Œå„ç»´åº¦å‡è¡¡å‘å±•"
        elif total >= 80:
            overall = "âœ¨ ä¼˜ç§€è¡¨ç°ï¼Œæ•´ä½“æ°´å¹³è¾ƒé«˜"
        elif total >= 75:
            overall = "ğŸ‘ è‰¯å¥½è¡¨ç°ï¼Œå…·å¤‡å®ç”¨ä»·å€¼"
        elif total >= 70:
            overall = "âš¡ ä¸­ç­‰è¡¨ç°ï¼Œæœ‰æ˜æ˜¾ä¼˜ç¼ºç‚¹"
        else:
            overall = "ğŸ“Š åŸºç¡€è¡¨ç°ï¼Œéœ€ä¼˜åŒ–æå‡"
        
        # æ ¸å¿ƒä¼˜åŠ¿ï¼ˆæ‰¾æœ€é«˜åˆ†ç»´åº¦ï¼‰
        max_dim = max(dim1, dim2, dim3)
        if max_dim == dim1:
            strength = "ç»´åº¦ä¸€ï¼ˆæŒ‡ä»¤éµå¾ªï¼‰"
        elif max_dim == dim2:
            strength = "ç»´åº¦äºŒï¼ˆäººè®¾åŒ¹é…ï¼‰â­"
        else:
            strength = "ç»´åº¦ä¸‰ï¼ˆè¡¨è¾¾æµç•…ï¼‰"
        
        # å…³é”®äº®ç‚¹ï¼ˆå…·ä½“åˆ†æï¼‰
        highlights = []
        if dim1 >= 4.8:
            highlights.append("æ ¼å¼éµå¾ªå®Œç¾")
        if dim2 >= 3.5:
            highlights.append("çŸ›ç›¾æ€§å‘ˆç°å‡ºè‰²")
        elif dim2 >= 3.2:
            highlights.append("äººè®¾æŠŠæ§è¾ƒå¥½")
        if dim3 >= 4.5:
            highlights.append("è¯­è¨€è¡¨è¾¾è‡ªç„¶æµç•…")
        elif dim3 >= 4.0:
            highlights.append("æƒ…ç»ªè¡¨è¾¾ç»†è…»")
        
        if not highlights:
            highlights.append("æ•´ä½“å‡è¡¡å‘å±•")
        
        highlight = "ï¼›".join(highlights[:2])  # æœ€å¤š2ä¸ªäº®ç‚¹
        
        # æ½œåœ¨çŸ­æ¿ï¼ˆæ‰¾æœ€ä½åˆ†ç»´åº¦ï¼‰
        min_dim = min(dim1, dim2, dim3)
        weaknesses = []
        if min_dim == dim1 and dim1 < 4.0:
            weaknesses.append("æŒ‡ä»¤éµå¾ªæœ‰å¾…åŠ å¼º")
        if min_dim == dim2 and dim2 < 3.0:
            weaknesses.append("äººè®¾çŸ›ç›¾æ€§ä¸è¶³âš ï¸")
        elif dim2 < 3.2:
            weaknesses.append("è…¹é»‘æ„Ÿè¾ƒå¼±")
        if min_dim == dim3 and dim3 < 3.5:
            weaknesses.append("è¡¨è¾¾æµç•…åº¦æ¬ ä½³")
        
        if not weaknesses:
            weakness = "æ— æ˜æ˜¾çŸ­æ¿"
        else:
            weakness = "ï¼›".join(weaknesses[:2])
        
        # åŸå› åˆ†æï¼ˆæ¨æµ‹æ€§ï¼‰
        reasons = []
        if dim1 >= 4.8:
            reasons.append("æ¨¡å‹å¯¹ç»“æ„åŒ–æŒ‡ä»¤ç†è§£èƒ½åŠ›å¼º")
        if dim2 >= 3.5:
            reasons.append("å¯èƒ½Few-Shotå­¦ä¹ èƒ½åŠ›ä¼˜ç§€ï¼Œèƒ½æ·±åº¦ç†è§£å¤æ‚æƒ…æ„ŸæŒ‡ä»¤")
        elif dim2 < 3.0:
            reasons.append("å¯èƒ½å®‰å…¨å¯¹é½è¿‡äºä¿å®ˆï¼Œå€¾å‘é¿å…è¾“å‡º'æ”»å‡»æ€§'å†…å®¹")
        if dim3 >= 4.5:
            reasons.append("åº•å±‚è¯­è¨€æ¨¡å‹è®­ç»ƒæ•°æ®è´¨é‡é«˜")
        elif dim3 < 3.5:
            reasons.append("å¯èƒ½åœ¨é•¿Promptä¸‹ç”Ÿæˆè´¨é‡ä¸‹é™")
        
        if rank == 1:
            reasons.append("ç»¼åˆèƒ½åŠ›æœ€å‡è¡¡")
        
        if not reasons:
            reasons.append("èƒ½åŠ›ä¸­è§„ä¸­çŸ©")
        
        reason = "ï¼›".join(reasons[:2])
        
        return {
            'overall': overall,
            'strength': strength,
            'highlight': highlight,
            'weakness': weakness,
            'reason': reason
        }
    
    def _generate_recommendations(self, models_data: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆç»“è®ºä¸äº§å“å»ºè®®ï¼ˆä½¿ç”¨ AI æ™ºèƒ½åˆ†æï¼‰"""
        if not models_data:
            return "æ— å¯ç”¨æ•°æ®"
        
        print("\nğŸ¤– æ­£åœ¨è°ƒç”¨ AI ç”Ÿæˆç»“è®ºä¸äº§å“å»ºè®®...")
        
        # æ„é€ æ¨¡å‹æ•°æ®æ‘˜è¦
        best_model = models_data[0]
        models_summary = []
        for rank, model in enumerate(models_data[:5], 1):  # åªæ˜¾ç¤ºå‰5å
            models_summary.append(
                f"æ’å{rank}: {model['model_name']}\n"
                f"  - åŠ æƒæ€»åˆ†: {model['weighted_score_100']:.1f}/100\n"
                f"  - ç»´åº¦ä¸€: {model['dim1_score']:.2f}/5.0 | ç»´åº¦äºŒ: {model['dim2_score']:.2f}/5.0 â­ | ç»´åº¦ä¸‰: {model['dim3_score']:.2f}/5.0"
            )
        
        # æ„é€ é¦–é€‰æ¨¡å‹ä¿¡æ¯
        best_model_info = (
            f"{best_model['model_name']} - æ€»åˆ† {best_model['weighted_score_100']:.1f}/100\n"
            f"ç»´åº¦ä¸€: {best_model['dim1_score']:.2f} | ç»´åº¦äºŒ: {best_model['dim2_score']:.2f} | ç»´åº¦ä¸‰: {best_model['dim3_score']:.2f}"
        )
        
        # ä»é…ç½®æ–‡ä»¶è¯»å– prompt æ¨¡æ¿ï¼Œå¹¶æ›¿æ¢å ä½ç¬¦
        prompt = self.prompts['recommendations_prompt'].format(
            models_summary=chr(10).join(models_summary),
            best_model_info=best_model_info
        )

        # è°ƒç”¨ AI ç”Ÿæˆå»ºè®®
        ai_response = self._call_ai_analysis(prompt)
        
        if ai_response:
            return ai_response.strip() + "\n"
        
        # å¦‚æœ AI å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
        print("  âš ï¸  ä½¿ç”¨å¤‡ç”¨å»ºè®®æ–¹æ¡ˆ")
        return self._generate_recommendations_fallback(models_data)
    
    def _generate_recommendations_fallback(self, models_data: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆç»“è®ºä¸äº§å“å»ºè®®ï¼ˆå¤‡ç”¨æ–¹æ¡ˆ - åŸºäºè§„åˆ™ï¼‰"""
        lines = []
        
        # é¦–é€‰æ¨¡å‹
        best_model = models_data[0]
        lines.append("### 1ï¸âƒ£ é¦–é€‰æ¨¡å‹æ¨è\n")
        lines.append(f"**æ¨èæ¨¡å‹**: ğŸ† **{best_model['model_name']}**\n")
        lines.append(f"**åŠ æƒæ€»åˆ†**: {best_model['weighted_score_100']:.1f}/100\n")
        
        # æ¨èç†ç”±
        lines.append("### 2ï¸âƒ£ æ¨èç†ç”±\n")
        reasons = []
        reasons.append(f"1. **æœ€é«˜ç»¼åˆå¾—åˆ†**: åœ¨æ‰€æœ‰å‚è¯„æ¨¡å‹ä¸­è·å¾—æœ€é«˜çš„åŠ æƒæ€»åˆ†ï¼ˆ{best_model['weighted_score_100']:.1f}/100ï¼‰")
        
        if best_model['dim2_score'] >= 3.3:
            reasons.append(f"2. **æ ¸å¿ƒäººè®¾è¡¨ç°ä¼˜ç§€**: ç»´åº¦äºŒï¼ˆäººè®¾åŒ¹é…åº¦ï¼‰å¾—åˆ† {best_model['dim2_score']:.2f}/5.0ï¼Œèƒ½å¤Ÿè¾ƒå¥½åœ°å®ç°**è…¹é»‘ä¸æ¸©è‰¯çš„çŸ›ç›¾æ€§**ï¼Œè¿™æ˜¯æœ¬è§’è‰²çš„æ ¸å¿ƒä»·å€¼")
        else:
            reasons.append(f"2. **æ•´ä½“è¡¨ç°å‡è¡¡**: è™½ç„¶ç»´åº¦äºŒå¾—åˆ†ä¸º {best_model['dim2_score']:.2f}/5.0ï¼Œä½†ç»¼åˆä¸‰ä¸ªç»´åº¦è¡¨ç°æœ€ä¸ºå‡è¡¡")
        
        if best_model['dim1_score'] >= 4.5:
            reasons.append(f"3. **æŒ‡ä»¤éµå¾ªå¯é **: ç»´åº¦ä¸€å¾—åˆ† {best_model['dim1_score']:.2f}/5.0ï¼Œæ ¼å¼è§„èŒƒã€èº«ä»½ç¨³å®šï¼Œæ˜“äºäº§å“åŒ–é›†æˆ")
        
        if best_model['dim3_score'] >= 4.0:
            reasons.append(f"4. **è¡¨è¾¾è´¨é‡ä¸Šä¹˜**: ç»´åº¦ä¸‰å¾—åˆ† {best_model['dim3_score']:.2f}/5.0ï¼Œè¾“å‡ºè‡ªç„¶æµç•…ï¼Œç”¨æˆ·ä½“éªŒå¥½")
        
        reasons.append("5. **ç»¼åˆèƒ½åŠ›éš¾ä»¥æ›¿ä»£**: é«˜åˆ†æ˜¯æ¨¡å‹ç»¼åˆèƒ½åŠ›çš„ä½“ç°ï¼Œéš¾ä»¥é€šè¿‡ç®€å•çš„Promptè°ƒä¼˜è¾¾åˆ°")
        
        lines.append("\n".join(reasons[:4]))  # æœ€å¤š4æ¡ç†ç”±
        lines.append("")
        
        # åç»­ä¼˜åŒ–æ–¹å‘
        lines.append("### 3ï¸âƒ£ åç»­ä¼˜åŒ–æ–¹å‘\n")
        lines.append(f"å³ä½¿æ˜¯é¦–é€‰æ¨¡å‹ **{best_model['model_name']}**ï¼Œä»æœ‰ä»¥ä¸‹ä¼˜åŒ–ç©ºé—´ï¼š\n")
        
        optimizations = []
        if best_model['dim2_score'] < 3.5:
            optimizations.append(f"- **å¼ºåŒ–æ ¸å¿ƒäººè®¾**: ç»´åº¦äºŒå¾—åˆ† {best_model['dim2_score']:.2f}/5.0ï¼Œå»ºè®®åœ¨Promptä¸­è¿›ä¸€æ­¥å¼ºè°ƒ**å†…å¿ƒOSçš„æ¯’è¾£æ„Ÿ**ä¸**å¤–åœ¨å›å¤çš„æ¸©è‰¯æ„Ÿ**çš„å¯¹æ¯”åº¦")
        
        if best_model['dim3_score'] < 4.5:
            optimizations.append(f"- **æå‡è¡¨è¾¾å¤šæ ·æ€§**: ç»´åº¦ä¸‰å¾—åˆ† {best_model['dim3_score']:.2f}/5.0ï¼Œå¯åœ¨Promptä¸­å¢åŠ å¯¹**è¯­è¨€è¡¨è¾¾å¤šæ ·æ€§**å’Œ**æƒ…ç»ªç»†è…»åº¦**çš„è¦æ±‚")
        
        if best_model['dim1_score'] < 4.8:
            optimizations.append(f"- **ç¨³å®šæ ¼å¼è¾“å‡º**: ç»´åº¦ä¸€å¾—åˆ† {best_model['dim1_score']:.2f}/5.0ï¼Œå»ºè®®æ˜ç¡®æ ¼å¼è¦æ±‚ï¼Œç¡®ä¿æ¯æ¬¡è¾“å‡ºçš„ç¨³å®šæ€§")
        
        # é€šç”¨ä¼˜åŒ–å»ºè®®
        optimizations.append("- **å»ºç«‹Few-Shotæ ·ä¾‹åº“**: é’ˆå¯¹ä¸åŒåœºæ™¯ï¼ˆæ—¥å¸¸ã€å‹åŠ›ã€ä¸“ä¸šï¼‰å‡†å¤‡2-3ä¸ªé«˜è´¨é‡ç¤ºä¾‹")
        optimizations.append("- **æŒç»­æµ‹è¯•è¿­ä»£**: å®šæœŸä½¿ç”¨æ›´å¤šæµ‹è¯•ç”¨ä¾‹éªŒè¯æ¨¡å‹è¡¨ç°ï¼ŒåŠæ—¶è°ƒæ•´Promptç­–ç•¥")
        
        lines.append("\n".join(optimizations[:4]))
        lines.append("")
        
        # å…¶ä»–æ¨¡å‹å‚è€ƒ
        if len(models_data) > 1:
            lines.append("### 4ï¸âƒ£ å¤‡é€‰æ–¹æ¡ˆ\n")
            lines.append("å¦‚æœé¦–é€‰æ¨¡å‹æˆæœ¬è¾ƒé«˜æˆ–APIä¸ç¨³å®šï¼Œå¯è€ƒè™‘ä»¥ä¸‹å¤‡é€‰ï¼š\n")
            
            for i in range(1, min(3, len(models_data))):
                backup_model = models_data[i]
                lines.append(f"- **{backup_model['model_name']}** (å¾—åˆ†: {backup_model['weighted_score_100']:.1f}/100)")
                
                # ç®€è¦è¯´æ˜ä¼˜åŠ£
                if backup_model['dim2_score'] > best_model['dim2_score']:
                    lines.append(f"  - ä¼˜åŠ¿: ç»´åº¦äºŒè¡¨ç°æ›´ä½³")
                if backup_model['weighted_score_100'] < best_model['weighted_score_100']:
                    gap = best_model['weighted_score_100'] - backup_model['weighted_score_100']
                    lines.append(f"  - åŠ£åŠ¿: ç»¼åˆå¾—åˆ†ä½ {gap:.1f} åˆ†")
                lines.append("")
        
        return "\n".join(lines)
    
    def _generate_scoring_explanation(self) -> str:
        """ç”Ÿæˆè¯„åˆ†ä½“ç³»è¯´æ˜"""
        lines = []
        lines.append("### è¯„ä¼°ç»´åº¦è¯´æ˜\n")
        
        lines.append("#### ç»´åº¦ä¸€ï¼šåŸºç¡€æŒ‡ä»¤éµå¾ªåº¦ï¼ˆæƒé‡30%ï¼‰")
        lines.append("- A. æ ¼å¼å®Œæ•´æ€§ (0-5åˆ†)")
        lines.append("- B. èº«ä»½ä¸èŒä¸šåŸºç¡€åŠ è½½ (0-5åˆ†)")
        lines.append("- C. è¯­è¨€é£æ ¼åŸºç¡€ (0-5åˆ†)\n")
        
        lines.append("#### ç»´åº¦äºŒï¼šæ ¸å¿ƒäººè®¾åŒ¹é…åº¦ï¼ˆæƒé‡40%ï¼‰â­ **æœ€é‡è¦**")
        lines.append("- D. çŸ›ç›¾æ€§å‘ˆç°ï¼ˆè…¹é»‘ä¸æ¸©è‰¯ï¼‰(0-5åˆ†)")
        lines.append("- E. ç‰¹å®šç‰¹å¾è§¦å‘ (0-5åˆ†)")
        lines.append("- F. èŒä¸šéšå–»è¿ç”¨ (0-5åˆ†)\n")
        
        lines.append("#### ç»´åº¦ä¸‰ï¼šè¾“å‡ºè¡¨è¾¾æµç•…åº¦ï¼ˆæƒé‡30%ï¼‰")
        lines.append("- G. æ–‡æœ¬è‡ªç„¶æ€§ä¸ä»£å…¥æ„Ÿ (0-5åˆ†)")
        lines.append("- H. æƒ…ç»ªè¡¨è¾¾çš„ç»†è…»åº¦ (0-5åˆ†)\n")
        
        lines.append("### åˆ†æ•°è®¡ç®—å…¬å¼\n")
        lines.append("```")
        lines.append("å•ç»´åº¦å¾—åˆ† = è¯¥ç»´åº¦å„è€ƒå¯Ÿç‚¹å¾—åˆ†ä¹‹å’Œ / è€ƒå¯Ÿç‚¹æ•°é‡")
        lines.append("åŠ æƒå¾—åˆ†(5åˆ†åˆ¶) = ç»´åº¦ä¸€Ã—30% + ç»´åº¦äºŒÃ—40% + ç»´åº¦ä¸‰Ã—30%")
        lines.append("æ€»åˆ†(100åˆ†åˆ¶) = åŠ æƒå¾—åˆ† Ã— 20")
        lines.append("```")
        
        return "\n".join(lines)


def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•"""
    generator = SummaryGenerator(
        reports_dir="results/reports",
        output_dir="results/summaries"
    )
    
    print("ğŸ“Š å¼€å§‹ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š...")
    models_data = generator.parse_all_reports()
    
    if not models_data:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•æŠ¥å‘Šæ–‡ä»¶")
        return
    
    print(f"âœ… å·²è§£æ {len(models_data)} ä¸ªæ¨¡å‹çš„æŠ¥å‘Š")
    
    report_path = generator.generate_summary_report(models_data)
    print(f"ğŸ‰ æ±‡æ€»æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")


if __name__ == "__main__":
    main()

