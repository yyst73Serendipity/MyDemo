"""
AIæ¨¡å‹APIå®¢æˆ·ç«¯å°è£…
æ”¯æŒå¤šä¸ªAIæœåŠ¡æä¾›å•†çš„ç»Ÿä¸€è°ƒç”¨æ¥å£
"""

import json
import time
from typing import Dict, Any, Optional
import requests
from abc import ABC, abstractmethod

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False


class BaseModelClient(ABC):
    """æ¨¡å‹å®¢æˆ·ç«¯åŸºç±»"""
    
    def __init__(self, config: Dict[str, Any]):
        self.name = config['name']
        self.model_id = config['model_id']
        self.api_key = config['api_key']
        self.base_url = config['base_url']
        self.params = config.get('params', {})
    
    @abstractmethod
    def chat(self, system_prompt: str, user_message: str) -> Dict[str, Any]:
        """å‘é€èŠå¤©è¯·æ±‚å¹¶è¿”å›å“åº”"""
        pass
    
    def _handle_error(self, error: Exception, attempt: int) -> None:
        """å¤„ç†APIè°ƒç”¨é”™è¯¯"""
        print(f"  âš ï¸  æ¨¡å‹ {self.name} ç¬¬ {attempt} æ¬¡è°ƒç”¨å¤±è´¥: {str(error)}")


class OpenAIClient(BaseModelClient):
    """OpenAI GPT å®¢æˆ·ç«¯"""
    
    def chat(self, system_prompt: str, user_message: str) -> Dict[str, Any]:
        url = f"{self.base_url}/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model_id,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            "temperature": self.params.get('temperature', 0.7),
            "max_tokens": self.params.get('max_tokens', 2000)
        }
        
        response = requests.post(url, headers=headers, json=payload, timeout=60)
        response.raise_for_status()
        
        result = response.json()
        return {
            "content": result['choices'][0]['message']['content'],
            "raw": result,
            "usage": result.get('usage', {})
        }


class GoogleGeminiClient(BaseModelClient):
    """Google Gemini å®¢æˆ·ç«¯"""
    
    def chat(self, system_prompt: str, user_message: str) -> Dict[str, Any]:
        url = f"{self.base_url}/models/{self.model_id}:generateContent?key={self.api_key}"
        headers = {
            "Content-Type": "application/json"
        }
        
        # Geminiçš„system instructionéœ€è¦ç‰¹æ®Šå¤„ç†
        full_prompt = f"{system_prompt}\n\nç”¨æˆ·è¾“å…¥ï¼š{user_message}"
        
        payload = {
            "contents": [
                {
                    "parts": [
                        {"text": full_prompt}
                    ]
                }
            ],
            "generationConfig": {
                "temperature": self.params.get('temperature', 0.7),
                "maxOutputTokens": self.params.get('max_output_tokens', 2000)
            }
        }
        
        response = requests.post(url, headers=headers, json=payload, timeout=60)
        response.raise_for_status()
        
        result = response.json()
        content = result['candidates'][0]['content']['parts'][0]['text']
        
        return {
            "content": content,
            "raw": result,
            "usage": result.get('usageMetadata', {})
        }


class DeepSeekClient(BaseModelClient):
    """DeepSeek å®¢æˆ·ç«¯"""
    
    def chat(self, system_prompt: str, user_message: str) -> Dict[str, Any]:
        url = f"{self.base_url}/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model_id,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            "temperature": self.params.get('temperature', 0.7),
            "max_tokens": self.params.get('max_tokens', 2000)
        }
        
        response = requests.post(url, headers=headers, json=payload, timeout=60)
        response.raise_for_status()
        
        result = response.json()
        return {
            "content": result['choices'][0]['message']['content'],
            "raw": result,
            "usage": result.get('usage', {})
        }


class QwenClient(BaseModelClient):
    """Qwen (é€šä¹‰åƒé—®) å®¢æˆ·ç«¯"""
    
    def chat(self, system_prompt: str, user_message: str) -> Dict[str, Any]:
        url = f"{self.base_url}/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model_id,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            "temperature": self.params.get('temperature', 0.7),
            "max_tokens": self.params.get('max_tokens', 2000)
        }
        
        response = requests.post(url, headers=headers, json=payload, timeout=60)
        response.raise_for_status()
        
        result = response.json()
        return {
            "content": result['choices'][0]['message']['content'],
            "raw": result,
            "usage": result.get('usage', {})
        }


class MoonshotClient(BaseModelClient):
    """Moonshot (Kimi) å®¢æˆ·ç«¯"""
    
    def chat(self, system_prompt: str, user_message: str) -> Dict[str, Any]:
        url = f"{self.base_url}/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model_id,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            "temperature": self.params.get('temperature', 0.7),
            "max_tokens": self.params.get('max_tokens', 2000)
        }
        
        response = requests.post(url, headers=headers, json=payload, timeout=60)
        response.raise_for_status()
        
        result = response.json()
        return {
            "content": result['choices'][0]['message']['content'],
            "raw": result,
            "usage": result.get('usage', {})
        }


class DMXAPIClient(BaseModelClient):
    """DMXAPI èšåˆå¹³å°å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨ OpenAI SDKï¼‰"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        
        if not OPENAI_AVAILABLE:
            raise ImportError(
                "ä½¿ç”¨ DMXAPI éœ€è¦å®‰è£… OpenAI SDKã€‚è¯·è¿è¡Œ: pip install openai"
            )
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
    
    def chat(self, system_prompt: str, user_message: str) -> Dict[str, Any]:
        """ä½¿ç”¨ OpenAI SDK è°ƒç”¨ DMXAPI"""
        try:
            response = self.client.chat.completions.create(
                model=self.model_id,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=self.params.get('temperature', 0.7),
                max_tokens=self.params.get('max_tokens', 4000)
            )
            
            # å°† OpenAI å“åº”å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            return {
                "content": response.choices[0].message.content,
                "raw": response.model_dump(),  # è½¬æ¢ä¸ºå­—å…¸
                "usage": {
                    "prompt_tokens": response.usage.prompt_tokens if response.usage else 0,
                    "completion_tokens": response.usage.completion_tokens if response.usage else 0,
                    "total_tokens": response.usage.total_tokens if response.usage else 0
                }
            }
        except Exception as e:
            # æ•è·å¹¶é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œä¿æŒä¸å…¶ä»–å®¢æˆ·ç«¯ä¸€è‡´
            raise Exception(f"DMXAPI è°ƒç”¨å¤±è´¥: {str(e)}")


class ModelClientFactory:
    """æ¨¡å‹å®¢æˆ·ç«¯å·¥å‚ç±»"""
    
    _client_map = {
        'openai': OpenAIClient,
        'google': GoogleGeminiClient,
        'deepseek': DeepSeekClient,
        'qwen': QwenClient,
        'moonshot': MoonshotClient,
        'dmxapi': DMXAPIClient
    }
    
    @classmethod
    def create_client(cls, config: Dict[str, Any]) -> BaseModelClient:
        """æ ¹æ®é…ç½®åˆ›å»ºå¯¹åº”çš„å®¢æˆ·ç«¯"""
        provider = config.get('provider', '').lower()
        
        if provider not in cls._client_map:
            raise ValueError(f"ä¸æ”¯æŒçš„æœåŠ¡æä¾›å•†: {provider}")
        
        client_class = cls._client_map[provider]
        return client_class(config)
    
    @classmethod
    def create_all_clients(cls, configs: list, logger=None, dmxapi_config: Dict = None) -> Dict[str, BaseModelClient]:
        """
        åˆ›å»ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹å®¢æˆ·ç«¯
        
        Args:
            configs: æ¨¡å‹é…ç½®åˆ—è¡¨
            logger: æ—¥å¿—è®°å½•å™¨
            dmxapi_config: DMXAPI ç»Ÿä¸€é…ç½®ï¼ˆåŒ…å« api_key å’Œ base_urlï¼‰
        """
        clients = {}
        for config in configs:
            if config.get('enabled', True):
                try:
                    # å¦‚æœæ˜¯ DMXAPI æä¾›å•†ï¼Œä½¿ç”¨ç»Ÿä¸€çš„ API Key å’Œ base_url
                    if config.get('provider') == 'dmxapi' and dmxapi_config:
                        config = config.copy()  # é¿å…ä¿®æ”¹åŸé…ç½®
                        config['api_key'] = dmxapi_config.get('api_key', '')
                        config['base_url'] = dmxapi_config.get('base_url', 'https://www.dmxapi.cn/v1')
                    
                    client = cls.create_client(config)
                    clients[config['name']] = client
                    msg = f"âœ… å·²åŠ è½½æ¨¡å‹: {config['name']}"
                    if logger:
                        logger.print(msg)
                    else:
                        print(msg)
                except Exception as e:
                    msg = f"âŒ åŠ è½½æ¨¡å‹ {config['name']} å¤±è´¥: {str(e)}"
                    if logger:
                        logger.print(msg)
                    else:
                        print(msg)
        
        return clients


def test_client(client: BaseModelClient, system_prompt: str, test_message: str, logger=None) -> Optional[Dict[str, Any]]:
    """æµ‹è¯•å•ä¸ªå®¢æˆ·ç«¯ï¼ŒåŒ…å«é‡è¯•é€»è¾‘"""
    max_retries = 3
    
    def log(msg):
        """ç»Ÿä¸€çš„æ—¥å¿—è¾“å‡º"""
        if logger:
            logger.print(msg)
        else:
            print(msg)
    
    for attempt in range(1, max_retries + 1):
        try:
            log(f"  ğŸ”„ å°è¯•ç¬¬ {attempt} æ¬¡è°ƒç”¨...")
            result = client.chat(system_prompt, test_message)
            log(f"  âœ… è°ƒç”¨æˆåŠŸ")
            return result
        except Exception as e:
            error_msg = f"  âš ï¸  æ¨¡å‹ {client.name} ç¬¬ {attempt} æ¬¡è°ƒç”¨å¤±è´¥: {str(e)}"
            log(error_msg)
            if attempt < max_retries:
                wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                log(f"  â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                log(f"  âŒ å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè·³è¿‡æ­¤æ¨¡å‹")
                return None
    
    return None

